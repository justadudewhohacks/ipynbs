{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "age_recognition_comparison.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justadudewhohacks/ipynbs/blob/master/age_recognition_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "E4nJnQmYm_2z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download Data"
      ]
    },
    {
      "metadata": {
        "id": "e6RkL5CMhNjQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "train_data_json_id = '1CDMRQdAhcws_g1yDw_29ZD5DNDDyi7Xw'\n",
        "test_data_json_id = '1_0dpT5HRTWocnK35KLQFDHzJiwV2-IQZ'\n",
        "\n",
        "utk_images_7z_id = '1c61PoUhIPKeoRzB0XDI23XMDyJaCfKSh'\n",
        "utk_landmarks_7z_id = '1Nxg7KKfEkDBWCqhusE1S6Edp6n3tTOuN'\n",
        "\n",
        "appareal_labels_json_id = '1_zfGunGuqyrftDJIEKw6NVJOS55vyOrh'\n",
        "appareal_images_7z_id = '1BDm6r88XLwDFsqOa2ZbbUtW1HDyHo5yA'\n",
        "appareal_landmarks_7z_id = '1Am36Tk-BnjfV1d8_iUpRcW-cPfQtAN0H'\n",
        "\n",
        "wiki_labels_json_id = '1BamAqN3tNEMh6kNQQ4C8nWf6gOA2IS6X'\n",
        "wiki_images_7z_id = '1Fy3pi-Pra1IsN9HDD268nRvXa1TbsryE'\n",
        "wiki_landmarks_7z_id = '1M-YeSGEEboVqNK8pTCJhbxeVaLp0TKJ4'\n",
        "\n",
        "if not os.path.exists('./data'):\n",
        "  os.makedirs('./data')\n",
        "if not os.path.exists('./data/utk'):\n",
        "  os.makedirs('./data/utk')\n",
        "if not os.path.exists('./data/appareal'):\n",
        "  os.makedirs('./data/appareal')\n",
        "if not os.path.exists('./data/wiki'):\n",
        "  os.makedirs('./data/wiki')\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "    \n",
        "print('downloading trainData.json and testData.json ...')\n",
        "drive.CreateFile({ 'id': train_data_json_id }).GetContentFile('./data/trainData.json')\n",
        "drive.CreateFile({ 'id': test_data_json_id }).GetContentFile('./data/testData.json')\n",
        "\n",
        "print('downloading utk data ...')\n",
        "drive.CreateFile({ 'id': utk_images_7z_id }).GetContentFile('./data/utk/images.7z')\n",
        "drive.CreateFile({ 'id': utk_landmarks_7z_id }).GetContentFile('./data/utk/landmarks.7z')\n",
        "\n",
        "print('downloading appareal data ...')\n",
        "drive.CreateFile({ 'id': appareal_labels_json_id }).GetContentFile('./data/appareal/labels.json')\n",
        "drive.CreateFile({ 'id': appareal_images_7z_id }).GetContentFile('./data/appareal/images.7z')\n",
        "drive.CreateFile({ 'id': appareal_landmarks_7z_id }).GetContentFile('./data/appareal/landmarks.7z')\n",
        "\n",
        "print('downloading wiki data ...')\n",
        "drive.CreateFile({ 'id': wiki_labels_json_id }).GetContentFile('./data/wiki/labels.json')\n",
        "drive.CreateFile({ 'id': wiki_images_7z_id }).GetContentFile('./data/wiki/images.7z')\n",
        "drive.CreateFile({ 'id': wiki_landmarks_7z_id }).GetContentFile('./data/wiki/landmarks.7z')\n",
        "  \n",
        "print('unzipping data...')\n",
        "\n",
        "!rm -rf ./sample_data\n",
        "!cd ./data/utk && p7zip -d ./images.7z >> ../../utk-images.unzip.txt\n",
        "!cd ./data/utk && p7zip -d ./landmarks.7z >> ../../utk-landmarks.unzip.txt\n",
        "!cd ./data/appareal && p7zip -d ./images.7z >> ../../appareal-images.unzip.txt\n",
        "!cd ./data/appareal && p7zip -d ./landmarks.7z >> ../../appareal-landmarks.unzip.txt\n",
        "!cd ./data/wiki && p7zip -d ./images.7z >> ../../wiki-images.unzip.txt\n",
        "!cd ./data/wiki && p7zip -d ./landmarks.7z >> ../../wiki-landmarks.unzip.txt\n",
        "!rm -rf *.unzip.txt\n",
        "print('done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V-zXGSH-Qw1k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Common"
      ]
    },
    {
      "metadata": {
        "id": "aJ1EFW1O1czU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/justadudewhohacks/image_augment.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSRUcrLYQvwO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import google.colab as colab\n",
        "import tensorflow as tf\n",
        "from augment.augment import augment\n",
        "\n",
        "def resize_preserve_aspect_ratio(img, size):\n",
        "  height, width = img.shape[:2]\n",
        "  max_dim = max(height, width)\n",
        "  ratio = size / float(max_dim)\n",
        "  shape = (height * ratio, width * ratio)\n",
        "  resized_img = cv2.resize(img, (int(round(width * ratio)), int(round(height * ratio))))\n",
        "\n",
        "  return resized_img\n",
        "\n",
        "def pad_to_square(img):\n",
        "  if len(img.shape) == 2:\n",
        "    img = np.expand_dims(img, axis = 2)\n",
        "\n",
        "  height, width, channels = img.shape\n",
        "  max_dim = max(height, width)\n",
        "  square_img = np.zeros([max_dim, max_dim, channels], dtype = img.dtype)\n",
        "\n",
        "  dx = math.floor(abs(max_dim - width) / 2)\n",
        "  dy = math.floor(abs(max_dim - height) / 2)\n",
        "  square_img[dy:dy + height,dx:dx + width] = img\n",
        "\n",
        "  return square_img\n",
        "\n",
        "def load_json(json_file_path):\n",
        "  with open(json_file_path) as json_file:  \n",
        "    return json.load(json_file)\n",
        "\n",
        "def shuffle_array(arr):\n",
        "  arr_clone = arr[:]\n",
        "  random.shuffle(arr_clone)\n",
        "  return arr_clone\n",
        "     \n",
        "class BatchLoader:\n",
        "  def __init__(\n",
        "    self, \n",
        "    data,\n",
        "    resolve_image_path,\n",
        "    extract_data_labels,\n",
        "    augment_image = None, \n",
        "    is_test = False,\n",
        "    start_epoch = None\n",
        "  ):\n",
        "    if not is_test and start_epoch == None:\n",
        "      raise Exception('DataLoader - start_epoch has to be defined in train mode')\n",
        "    \n",
        "    self.data = data\n",
        "    self.resolve_image_path = resolve_image_path\n",
        "    self.extract_data_labels = extract_data_labels\n",
        "    self.augment_image = augment_image\n",
        "    self.is_test = is_test\n",
        "    self.epoch = start_epoch\n",
        "    self.buffered_data = shuffle_array(self.data) if not is_test else self.data\n",
        "    self.current_idx = 0\n",
        " \n",
        "  def get_end_idx(self):\n",
        "    return len(self.buffered_data)\n",
        "   \n",
        "  def load_image(self, data, image_size):\n",
        "    db = data['db']\n",
        "    img_file = data['file']\n",
        "    file_suffix = 'chip_0' if db == 'utk' else ('face_0' if db == 'appareal' else '')\n",
        "    landmarks_file = img_file.replace(file_suffix + '.jpg', file_suffix + '.json')\n",
        "    landmarks_file_path = './data/' + db + '/landmarks/' + landmarks_file\n",
        "\n",
        "    img = cv2.imread(self.resolve_image_path(data))\n",
        "    if img is None:\n",
        "      raise Exception('failed to read image from path: ' + img_file_path)\n",
        "\n",
        "    if (self.augment_image is not None):\n",
        "      img = self.augment_image(img, data)\n",
        "\n",
        "    img = pad_to_square(resize_preserve_aspect_ratio(img, image_size))\n",
        "\n",
        "    return img\n",
        "\n",
        "  def load_image_batch(self, datas, image_size):\n",
        "    preprocessed_imgs = []\n",
        "    for data in datas:\n",
        "      preprocessed_imgs.append(self.load_image(data, image_size))\n",
        "    return np.stack(preprocessed_imgs, axis = 0)\n",
        "    \n",
        "  def load_labels(self, datas):\n",
        "    labels = []\n",
        "    for data in datas:\n",
        "      labels.append(self.extract_data_labels(data))\n",
        "    return np.stack(labels, axis = 0)\n",
        "    \n",
        "  def next_batch(self, batch_size, image_size = 112):\n",
        "    if batch_size < 1:\n",
        "      raise Exception('DataLoader.next_batch - invalid batch_size: ' + str(batch_size))\n",
        "      \n",
        "    \n",
        "    from_idx = self.current_idx\n",
        "    to_idx = self.current_idx + batch_size\n",
        "    \n",
        "    # end of epoch\n",
        "    if (to_idx > len(self.buffered_data)):\n",
        "      if self.is_test:\n",
        "        to_idx = len(self.buffered_data)\n",
        "        if to_idx == self.current_idx:\n",
        "          return None\n",
        "      else:\n",
        "        self.epoch += 1\n",
        "        self.buffered_data = self.buffered_data[from_idx:] + shuffle_array(self.data)  \n",
        "        from_idx = 0\n",
        "        to_idx = batch_size\n",
        "      \n",
        "    self.current_idx = to_idx\n",
        "    \n",
        "    next_data = self.buffered_data[from_idx:to_idx]\n",
        "      \n",
        "    batch_x = self.load_image_batch(next_data, image_size)\n",
        "    batch_y = self.load_labels(next_data)\n",
        "    \n",
        "    return batch_x, batch_y\n",
        "  \n",
        "\n",
        "'''\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "utility\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "def gpu_session(callback):\n",
        "  config = tf.ConfigProto()\n",
        "  config.gpu_options.allow_growth = True\n",
        "  config.allow_soft_placement = True\n",
        "  config.log_device_placement = True\n",
        "  with tf.Session(config = config) as session:\n",
        "    with tf.device('/gpu:0'):\n",
        "      callback(session)\n",
        "\n",
        "def get_checkpoint(epoch):\n",
        "  return model_name + '.ckpt-' + str(epoch)\n",
        "\n",
        "def download_epoch_files(start, end):\n",
        "  for epoch in range(start, end):\n",
        "    colab.files.download('epoch_' + str(epoch) + '.txt')\n",
        "    colab.files.download(get_checkpoint(epoch) + '.index') \n",
        "    colab.files.download(get_checkpoint(epoch) + '.meta') \n",
        "    colab.files.download(get_checkpoint(epoch) + '.data-00000-of-00001')\n",
        "\n",
        "def save_weights(var_list, checkpoint_file):\n",
        "  checkpoint_data = np.array([])\n",
        "  meta_data = []\n",
        "  for var in var_list:\n",
        "    meta_data.append({ 'shape': var.get_shape().as_list(), 'name': var.name })\n",
        "    checkpoint_data = np.append(checkpoint_data, var.eval().flatten())\n",
        "    \n",
        "  meta_json = open(checkpoint_file + '.json', 'w')\n",
        "  meta_json.write(json.dumps(meta_data))\n",
        "  meta_json.close()\n",
        "  np.save(checkpoint_file, checkpoint_data)\n",
        "\n",
        "\n",
        "'''\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "Data Loader\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "\n",
        "appareal_labels = load_json('./data/appareal/labels.json')\n",
        "wiki_labels = load_json('./data/wiki/labels.json')\n",
        "\n",
        "def extract_data_labels(data):\n",
        "  db = data['db']\n",
        "  img_file = data['file']\n",
        "\n",
        "  if db == 'utk':\n",
        "    age = int(float(img_file.split('_')[0]))\n",
        "    return age\n",
        "  elif db == 'appareal':\n",
        "    age = appareal_labels[img_file]['age']\n",
        "    return age\n",
        "  elif db == 'wiki':\n",
        "    age = wiki_labels[img_file]['age']\n",
        "    return age\n",
        "  else: raise('unknown db: ' + db)\n",
        "    \n",
        "def resolve_image_path(data):\n",
        "  db = data['db']\n",
        "  img_file = data['file']\n",
        "  return './data/' + db + '/cropped-images/' + img_file   \n",
        "\n",
        "def min_bbox(landmarks):\n",
        "  min_x, min_y, max_x, max_y = 1.0, 1.0, 0, 0\n",
        "  for pt in landmarks:\n",
        "    min_x = pt['x'] if pt['x'] < min_x else min_x\n",
        "    min_y = pt['y'] if pt['y'] < min_y else min_y\n",
        "    max_x = max_x if pt['x'] < max_x else pt['x']\n",
        "    max_y = max_y if pt['y'] < max_y else pt['y']\n",
        "\n",
        "  return [min_x, min_y, max_x, max_y]\n",
        "\n",
        "def augment_image(img, data):\n",
        "  db = data['db']\n",
        "  img_file = data['file']\n",
        "  file_suffix = 'chip_0' if db == 'utk' else ('face_0' if db == 'appareal' else '')\n",
        "  landmarks_file = img_file.replace(file_suffix + '.jpg', file_suffix + '.json')\n",
        "  landmarks_file_path = './data/' + db + '/landmarks/' + landmarks_file\n",
        "\n",
        "  landmarks = load_json(landmarks_file_path)\n",
        "  \n",
        "  \n",
        "  intensity_config = { 'alpha': random.uniform(0.5, 1.5), 'beta': random.uniform(-20, 20) }\n",
        "  blur_config = { 'kernel_size':  random.choice([0, 3, 5, 7, 9, 11]), 'std_dev': random.uniform(0.5, 1.5) }\n",
        "  blur_prob = 0.5\n",
        "  flip_prob = 0.5\n",
        "  gray_prob = 0.2\n",
        "\n",
        "  return augment(\n",
        "    img,\n",
        "    random_crop = min_bbox(landmarks),\n",
        "    flip = random.random() < flip_prob,\n",
        "    rotation_angle = random.uniform(-15, 15),\n",
        "    shear = [random.uniform(0.0, 0.2), random.uniform(0.0, 0.2)],\n",
        "    stretch = { 'stretch_x': random.uniform(1.0, 1.4), 'stretch_y': random.uniform(1.0, 1.4) },\n",
        "    intensity = intensity_config,\n",
        "    blur = blur_config if random.random() < blur_prob else None,\n",
        "    hsv = [random.uniform(-5, 5), random.uniform(-15, 15), random.uniform(-20, 20)],\n",
        "    to_gray = random.random() < gray_prob\n",
        "    #rotation_angle = random.uniform(-5, 5),\n",
        "    #blur = { 'kernel_size':  random.choice([3, 5, 7]), 'std_dev': random.uniform(0.8, 1.2) },\n",
        "    #intensity = { 'alpha': random.uniform(0.8, 1.2), 'beta': random.uniform(-10, 10) },\n",
        "    #to_gray = random.random() < 0.1\n",
        "  )\n",
        "\n",
        "class DataLoader(BatchLoader):\n",
        "  def __init__(self, data, with_augmentation = False, start_epoch = None, is_test = False):\n",
        "    BatchLoader.__init__(\n",
        "      self, \n",
        "      data, \n",
        "      resolve_image_path, \n",
        "      extract_data_labels, \n",
        "      augment_image = augment_image if with_augmentation else None, \n",
        "      start_epoch = start_epoch, \n",
        "      is_test = is_test\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UwJTeoQIw4hV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ResNet50\n",
        "\n",
        "https://github.com/yu4u/age-gender-estimation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "idrFlaNbWqoA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/yu4u/age-gender-estimation/releases/download/v0.5/age_only_resnet50_weights.061-3.300-4.410.hdf5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GdxJc_4QxH_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84fb0bd5-200e-4a6f-8a35-77c175a3cc50"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import ResNet50, InceptionResNetV2\n",
        "from keras.layers import Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "def get_resnet50_model():\n",
        "  base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling=\"avg\")\n",
        "  prediction = Dense(units=101, kernel_initializer=\"he_normal\", use_bias=False, activation=\"softmax\", \n",
        "                     name=\"pred_age\")(base_model.output)\n",
        "  model = Model(inputs = base_model.input, outputs = prediction)\n",
        "  model.load_weights('./age_only_resnet50_weights.061-3.300-4.410.hdf5')\n",
        "  model.compile(optimizer = SGD(), loss = \"categorical_crossentropy\")\n",
        "  def predict(x):\n",
        "    return model.predict(x, batch_size = x.shape[0])\n",
        "  \n",
        "  return predict"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "bJp6to1725gC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Caffe Models\n",
        "\n",
        "https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/"
      ]
    },
    {
      "metadata": {
        "id": "F4IG1g-z219V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt install -y caffe-cuda\n",
        "#!apt install -y caffe-cpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2d0VBriXAtn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import caffe\n",
        "caffe.set_device(0)\n",
        "caffe.set_mode_gpu()\n",
        "\n",
        "def get_caffe_model(prototxt, caffemodel):\n",
        "  net = caffe.Net(prototxt, caffemodel, caffe.TEST)\n",
        "  def predict(x):\n",
        "    x = np.swapaxes(np.swapaxes(x, 2, 3), 1, 2)\n",
        "    net.blobs['data'].data[...] = x\n",
        "    return net.forward()['prob']\n",
        "  \n",
        "  return predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ePo6wywNrk1H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Real age estimation trained on IMDB-WIKI"
      ]
    },
    {
      "metadata": {
        "id": "4BxK1Wtj1tcC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/dex_imdb_wiki.caffemodel\n",
        "!wget -O dex_imdb_wiki.prototxt https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/age.prototxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "yO38s7-irzN-"
      },
      "cell_type": "markdown",
      "source": [
        "## Apparent age estimation trained on LAP dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q2F-VhY72oIg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/dex_chalearn_iccv2015.caffemodel\n",
        "!wget -O dex_chalearn_iccv2015.prototxt https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/age.prototxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-rVMRA-t2sbR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test"
      ]
    },
    {
      "metadata": {
        "id": "CzzsF9iJ1zw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4161f77c-de08-47e3-c266-b4433ce84824"
      },
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "batch_size = 1\n",
        "dbs = ['utk', 'wiki', 'appareal']\n",
        "test_data = load_json('./data/testData.json')\n",
        "\n",
        "total_loss = 0\n",
        "iteration_count = 0\n",
        "total_loss_db = 0\n",
        "iteration_count_db = 0\n",
        "ts_test = time.time()\n",
        "\n",
        "def compute_loss(pred, batch_y, is_dex = True):\n",
        "  if is_dex:\n",
        "    age = np.sum(pred * np.arange(101), axis = 1)\n",
        "  else:\n",
        "    age = np.argmax(pred, axis = 1)\n",
        "     \n",
        "  return np.sum(np.absolute(age - batch_y))\n",
        "\n",
        "# dex or argmax\n",
        "is_dex = True\n",
        "\n",
        "# model\n",
        "\n",
        "#predict = get_resnet50_model()\n",
        "#predict = get_caffe_model('dex_imdb_wiki.prototxt', 'dex_imdb_wiki.caffemodel')\n",
        "#predict = get_caffe_model('dex_chalearn_iccv2015.prototxt', 'dex_chalearn_iccv2015.caffemodel')\n",
        "\n",
        "print('model loaded')\n",
        "\n",
        "for db in dbs:\n",
        "  db_data = []\n",
        "  for data in test_data:\n",
        "    if data['db'] == db:\n",
        "      db_data.append(data)\n",
        "\n",
        "  data_loader = DataLoader(db_data, is_test = True)\n",
        "  next_batch = data_loader.next_batch(batch_size, image_size = image_size)\n",
        "  \n",
        "  while next_batch != None:\n",
        "    batch_x, batch_y = next_batch\n",
        "    pred = predict(batch_x)\n",
        "    loss = compute_loss(pred, batch_y, is_dex = is_dex)\n",
        "    total_loss += loss\n",
        "    total_loss_db += loss\n",
        "    iteration_count += 1\n",
        "    iteration_count_db += 1\n",
        "    next_batch = data_loader.next_batch(batch_size, image_size = image_size)\n",
        "\n",
        "  print(str(db) + \", avg_loss= \" + str(total_loss_db / iteration_count_db))\n",
        "  total_loss_db = 0\n",
        "  iteration_count_db = 0\n",
        "\n",
        "print(\"avg_loss= \" + str(total_loss / iteration_count))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model loaded\n",
            "utk, avg_loss= 11.32617987261595\n",
            "wiki, avg_loss= 11.568283441558872\n",
            "appareal, avg_loss= 9.298751416665148\n",
            "avg_loss= 11.216863203419415\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}