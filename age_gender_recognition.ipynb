{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "age_gender_recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justadudewhohacks/ipynbs/blob/master/age_gender_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeObtjLNxBqx",
        "colab_type": "text"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm3eajF2xAx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install git+https://github.com/justadudewhohacks/image_augment.py\n",
        "!pip install git+https://github.com/justadudewhohacks/colabsnippets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hof5xhmLh3uf"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vh2ay-TCh3ul",
        "outputId": "6ed5cbe3-6a81-45e7-90a1-5ddd6d1661ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1938
        }
      },
      "source": [
        "from colabsnippets.DataDownloader import DataDownloader\n",
        "from colabsnippets.utils import load_json\n",
        "\n",
        "data_downloader = DataDownloader(data_dir = './data')\n",
        "\n",
        "data_downloader.drive.CreateFile({ 'id': '17BPRF73QXEP65NP3sWwBNPbKjT1MJzuM' }).GetContentFile('./age_gender_ethnicity_dbs.json')\n",
        "dbs = load_json('./age_gender_ethnicity_dbs.json')\n",
        "\n",
        "data_downloader.download_data(dbs)\n",
        "\n",
        "print('downloading data split and labels ...')\n",
        "data_downloader.drive.CreateFile({ 'id': '1Vndxi_V0s3USsE9c6evRAPQHZB1rg-HC' }).GetContentFile('./data/trainData.json')\n",
        "data_downloader.drive.CreateFile({ 'id': '1jd7lYHv0pR4nlNFLgBeHHInHeoGKKL7T' }).GetContentFile('./data/testData.json')\n",
        "data_downloader.drive.CreateFile({ 'id': '1z2C1M0zyf9xF2faCQJUsaFYx9u9vSDep' }).GetContentFile('./data/chalearn/labels.json')\n",
        "data_downloader.drive.CreateFile({ 'id': '1SC3PuQj-CQb4O87YHIJDu1J7APZvQRsa' }).GetContentFile('./data/wiki/labels.json')\n",
        "data_downloader.drive.CreateFile({ 'id': '1KeqNCL35SR5MeJkkdEiqLxBhZihDn4Sq' }).GetContentFile('./data/imdb/labels.json')\n",
        "data_downloader.drive.CreateFile({ 'id': '1nU6xuPV2R-TRg388eGftgGwLrj-n2Ra_' }).GetContentFile('./data/megaage/labels.json')\n",
        "data_downloader.drive.CreateFile({ 'id': '1_SzULpNyws920UUZdcVDKBGDvDNpFSf0' }).GetContentFile('./data/megaage-asian/labels.json')\n",
        "\n",
        "print('done!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading data for db: fgnet\n",
            "downloading data for shard 0\n",
            "unzipping images done in 0.9271001815795898s\n",
            "unzipping landmarks done in 0.26310300827026367s\n",
            "downloading data for db: chalearn\n",
            "downloading data for shard 0\n",
            "unzipping images done in 14.007997274398804s\n",
            "unzipping landmarks done in 9.231802463531494s\n",
            "downloading data for db: utk\n",
            "downloading data for shard 0\n",
            "unzipping images done in 16.64055633544922s\n",
            "unzipping landmarks done in 13.267534732818604s\n",
            "downloading data for shard 1\n",
            "unzipping images done in 16.76087999343872s\n",
            "unzipping landmarks done in 12.440708637237549s\n",
            "downloading data for shard 2\n",
            "unzipping images done in 16.804337739944458s\n",
            "unzipping landmarks done in 12.240557670593262s\n",
            "downloading data for db: megaage\n",
            "downloading data for shard 0\n",
            "unzipping images done in 13.258168458938599s\n",
            "unzipping landmarks done in 11.733147382736206s\n",
            "downloading data for shard 1\n",
            "unzipping images done in 12.739650964736938s\n",
            "unzipping landmarks done in 10.997202634811401s\n",
            "downloading data for shard 2\n",
            "unzipping images done in 12.767117738723755s\n",
            "unzipping landmarks done in 11.460566520690918s\n",
            "downloading data for shard 3\n",
            "unzipping images done in 13.237601280212402s\n",
            "unzipping landmarks done in 11.964378118515015s\n",
            "downloading data for shard 4\n",
            "unzipping images done in 12.86354112625122s\n",
            "unzipping landmarks done in 10.85804295539856s\n",
            "downloading data for db: megaage-asian\n",
            "downloading data for shard 0\n",
            "unzipping images done in 14.439360618591309s\n",
            "unzipping landmarks done in 12.466429948806763s\n",
            "downloading data for shard 1\n",
            "unzipping images done in 15.460927963256836s\n",
            "unzipping landmarks done in 12.50943899154663s\n",
            "downloading data for shard 2\n",
            "unzipping images done in 14.160087823867798s\n",
            "unzipping landmarks done in 12.31388521194458s\n",
            "downloading data for shard 3\n",
            "unzipping images done in 14.147135972976685s\n",
            "unzipping landmarks done in 12.273583173751831s\n",
            "downloading data for shard 4\n",
            "unzipping images done in 15.469310760498047s\n",
            "unzipping landmarks done in 12.432385683059692s\n",
            "downloading data for db: wiki\n",
            "downloading data for shard 0\n",
            "unzipping images done in 27.18274712562561s\n",
            "unzipping landmarks done in 21.87918996810913s\n",
            "downloading data for shard 1\n",
            "unzipping images done in 28.250401258468628s\n",
            "unzipping landmarks done in 22.87457823753357s\n",
            "downloading data for shard 2\n",
            "unzipping images done in 28.367507219314575s\n",
            "unzipping landmarks done in 22.313992500305176s\n",
            "downloading data for db: cacd\n",
            "downloading data for shard 0\n",
            "unzipping images done in 22.20949959754944s\n",
            "unzipping landmarks done in 18.712199211120605s\n",
            "downloading data for shard 1\n",
            "unzipping images done in 24.332318544387817s\n",
            "unzipping landmarks done in 17.780744791030884s\n",
            "downloading data for shard 2\n",
            "unzipping images done in 22.320314407348633s\n",
            "unzipping landmarks done in 17.849984645843506s\n",
            "downloading data for shard 3\n",
            "unzipping images done in 23.538228511810303s\n",
            "unzipping landmarks done in 17.83281898498535s\n",
            "downloading data for shard 4\n",
            "unzipping images done in 22.499532222747803s\n",
            "unzipping landmarks done in 18.82474112510681s\n",
            "downloading data for shard 5\n",
            "unzipping images done in 22.834655046463013s\n",
            "unzipping landmarks done in 17.810688018798828s\n",
            "downloading data for db: imdb\n",
            "downloading data for shard 0\n",
            "unzipping images done in 22.61263108253479s\n",
            "unzipping landmarks done in 17.538395643234253s\n",
            "downloading data for shard 1\n",
            "unzipping images done in 22.5974543094635s\n",
            "unzipping landmarks done in 16.03809690475464s\n",
            "downloading data for shard 2\n",
            "unzipping images done in 24.70370364189148s\n",
            "unzipping landmarks done in 16.33044123649597s\n",
            "downloading data for shard 3\n",
            "unzipping images done in 22.558801412582397s\n",
            "unzipping landmarks done in 15.876621961593628s\n",
            "downloading data for shard 4\n",
            "unzipping images done in 24.19420576095581s\n",
            "unzipping landmarks done in 16.184423685073853s\n",
            "downloading data for shard 5\n",
            "unzipping images done in 23.299465894699097s\n",
            "unzipping landmarks done in 15.98129677772522s\n",
            "downloading data for shard 6\n",
            "unzipping images done in 25.31335186958313s\n",
            "unzipping landmarks done in 16.041129112243652s\n",
            "downloading data for shard 7\n",
            "unzipping images done in 23.05742049217224s\n",
            "unzipping landmarks done in 16.053702116012573s\n",
            "downloading data for shard 8\n",
            "unzipping images done in 23.6005437374115s\n",
            "unzipping landmarks done in 16.113201379776s\n",
            "downloading data for shard 9\n",
            "unzipping images done in 24.687246799468994s\n",
            "unzipping landmarks done in 17.118643522262573s\n",
            "download_data - total time: 1273.708373785019s\n",
            "downloading data split and labels ...\n",
            "done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY0yDy-HnN79",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-zXGSH-Qw1k",
        "colab_type": "text"
      },
      "source": [
        "## Common"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSRUcrLYQvwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import types\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from augment import ImageAugmentor\n",
        "from colabsnippets.utils import load_json\n",
        "from colabsnippets import BatchLoader\n",
        "\n",
        "'''\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "Data Loader\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "\n",
        "chalearn_labels = load_json('./data/chalearn/labels.json')\n",
        "wiki_labels = load_json('./data/wiki/labels.json')\n",
        "imdb_labels = load_json('./data/imdb/labels.json')\n",
        "megaage_labels = load_json('./data/megaage/labels.json')\n",
        "megaage_asian_labels = load_json('./data/megaage-asian/labels.json')\n",
        "\n",
        "# 0 male, 1 female\n",
        "def gender_code_to_label(gender_code, safe_mode = True):\n",
        "  gender = 'female' if gender_code == 1 else ('male' if gender_code == 0 else None)\n",
        "  if gender is None and safe_mode:\n",
        "    raise Exception (\"gender_code_to_label - invalid gender code '{}'\".format(gender_code))\n",
        "  return gender\n",
        "  \n",
        "# 0 male, 1 female\n",
        "def get_gender_one_hot(label):\n",
        "  if label == 'male':\n",
        "    return [1, 0]\n",
        "  if label == 'female':\n",
        "    return [0, 1]\n",
        "  raise Exception('unknown gender label: ' + str(label))\n",
        "  \n",
        "  \n",
        "def extract_data_labels(data):\n",
        "  db = data['db']\n",
        "  img_file = data['file']\n",
        "\n",
        "  if db == 'utk':\n",
        "    age = int(float(img_file.split('_')[0]))\n",
        "    gender_code = int(img_file.split('_')[1])\n",
        "    gender = gender_code_to_label(gender_code, safe_mode = False)\n",
        "    if gender is None:\n",
        "      print (\"utk invalid gender code '{}' for file: {}\".format(gender_code, img_file))\n",
        "      return age, None\n",
        "    return age, gender\n",
        "  if db == 'fgnet':\n",
        "    age = int(float(img_file.split('_')[0].split('A')[1][0:2]))\n",
        "    return age, None\n",
        "  elif db == 'chalearn':\n",
        "    age = chalearn_labels[img_file]['realAge']\n",
        "    gender = chalearn_labels[img_file]['gender']\n",
        "    return age, gender\n",
        "  elif db == 'megaage':\n",
        "    age = megaage_labels[img_file]\n",
        "    return age, None\n",
        "  elif db == 'megaage-asian':\n",
        "    age = megaage_asian_labels[img_file]\n",
        "    return age, None\n",
        "  elif db == 'wiki':\n",
        "    age = wiki_labels[img_file]['age']\n",
        "    gender = wiki_labels[img_file]['gender']\n",
        "    return age, gender\n",
        "  elif db == 'imdb':\n",
        "    age = imdb_labels[img_file]['age']\n",
        "    gender = imdb_labels[img_file]['gender']\n",
        "    return age, gender\n",
        "  elif db == 'cacd':\n",
        "    age = int(img_file[0:2])\n",
        "    return age, None\n",
        "  else: raise Exception('unknown db: ' + db)\n",
        "    \n",
        "def resolve_image_path(data):\n",
        "  db = data['db']\n",
        "  img_file = data['file']\n",
        "  img_dir = \"images-shard{}\".format(data['shard']) if 'shard' in data else 'cropped-images'\n",
        "  img_path = \"./data/{}/{}/{}\".format(db, img_dir, img_file)\n",
        "  return img_path\n",
        "\n",
        "def min_bbox(landmarks):\n",
        "  min_x, min_y, max_x, max_y = 1.0, 1.0, 0, 0\n",
        "  for pt in landmarks:\n",
        "    min_x = pt['x'] if pt['x'] < min_x else min_x\n",
        "    min_y = pt['y'] if pt['y'] < min_y else min_y\n",
        "    max_x = max_x if pt['x'] < max_x else pt['x']\n",
        "    max_y = max_y if pt['y'] < max_y else pt['y']\n",
        "\n",
        "  return [min_x, min_y, max_x, max_y]\n",
        "\n",
        "def augment_image_factory(image_augmentor):\n",
        "  def augment_image(img, data):\n",
        "    db = data['db']\n",
        "    img_file = data['file']\n",
        "    file_suffix = 'chip_0' if db == 'utk' else ('face_0' if db == 'appareal' else '')\n",
        "    landmarks_file = img_file.replace(file_suffix + '.jpg', file_suffix + '.json')\n",
        "    landmarks_dir = \"landmarks-shard{}\".format(data['shard']) if 'shard' in data else 'landmarks'\n",
        "    landmarks_path = \"./data/{}/{}/{}\".format(db, landmarks_dir, landmarks_file)\n",
        "    return image_augmentor.augment(img, random_crop = min_bbox(load_json(landmarks_path)))\n",
        "  return augment_image\n",
        "\n",
        "class DataLoader(BatchLoader):\n",
        "  def __init__(self, data, image_augmentor = None, start_epoch = None, is_test = False):   \n",
        "    BatchLoader.__init__(\n",
        "      self, \n",
        "      data if type(data) is types.FunctionType else lambda: data, \n",
        "      resolve_image_path, \n",
        "      extract_data_labels, \n",
        "      augment_image = augment_image_factory(image_augmentor) if image_augmentor is not None else None, \n",
        "      start_epoch = start_epoch, \n",
        "      is_test = is_test\n",
        "    )\n",
        "\n",
        "\n",
        "'''\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "utility\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "def gpu_session(callback):\n",
        "  config = tf.ConfigProto()\n",
        "  config.gpu_options.allow_growth = True\n",
        "  config.allow_soft_placement = True\n",
        "  config.log_device_placement = True\n",
        "  with tf.Session(config = config) as session:\n",
        "    with tf.device('/gpu:0'):\n",
        "      return callback(session)\n",
        "\n",
        "def get_checkpoint(epoch):\n",
        "  return model_name + '.ckpt-' + str(epoch)\n",
        "\n",
        "def filter_data_in_age_range(data, min_age, max_age):\n",
        "  filtered_data = []\n",
        "  for d in data:\n",
        "    age, _ = extract_data_labels(d)\n",
        "    if (min_age <= age and age <= max_age):\n",
        "      filtered_data.append(d)\n",
        "  return filtered_data\n",
        "\n",
        "def forward_dbs_factory(all_data, dbs, transform_label = lambda x: x, transform_prediction = lambda x: x):\n",
        "  def forward_dbs(forward):\n",
        "    results = []\n",
        "\n",
        "    for db in dbs:\n",
        "      db_data = []\n",
        "      for data in all_data:\n",
        "        if data['db'] == db:\n",
        "          db_data.append(data)\n",
        "\n",
        "      data_loader = DataLoader(db_data, is_test = True)\n",
        "\n",
        "      db_results = []\n",
        "      next_batch = data_loader.next_batch(batch_size, image_size = image_size)\n",
        "      while next_batch != None:\n",
        "        batch_x, batch_y = next_batch\n",
        "        pred_age, pred_gender = forward(batch_x)\n",
        "        for idx, y in enumerate(batch_y):\n",
        "          db_results.append((db, transform_label(y), transform_prediction(pred_age[idx], pred_gender[idx])))\n",
        "        next_batch = data_loader.next_batch(batch_size, image_size = image_size)\n",
        "\n",
        "      results += db_results\n",
        "\n",
        "    return results\n",
        "  return forward_dbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ_9nRRuoHuF",
        "colab_type": "text"
      },
      "source": [
        "## Train Age Range Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4S3cqgioJTN",
        "colab_type": "code",
        "outputId": "f1d50204-8415-48d2-ba04-6e4d6daa4db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "from colabsnippets.age_gender_recognition import AgeGenderXceptionTiny\n",
        "from colabsnippets.utils import shuffle_array\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "net = AgeGenderXceptionTiny(num_blocks = 2)\n",
        "model_name = net.name + '_augmented4_blocks2_5_5000_rgb'\n",
        "\n",
        "# training parameters\n",
        "learning_rate = 0.00001\n",
        "start_epoch = 164\n",
        "end_epoch = 2000\n",
        "batch_size = 32\n",
        "image_size = 112\n",
        "\n",
        "image_augmentor = ImageAugmentor.load('./augmentor_4.json')\n",
        "\n",
        "train_data = load_json('./data/trainData.json')\n",
        "\n",
        "def get_epoch_data():\n",
        "  age_category_range = 5\n",
        "  max_per_category = 5000\n",
        "  num_bins = int(120 / age_category_range)\n",
        "  data_by_age_category = []\n",
        "  for i in range(0, num_bins):\n",
        "    data_by_age_category.append([])\n",
        "  \n",
        "  for data in train_data:\n",
        "    true_age, _ = extract_data_labels(data)\n",
        "    hist_bin = int(math.floor(true_age / age_category_range))\n",
        "    data_by_age_category[hist_bin].append(data)\n",
        "  \n",
        "  epoch_data = []\n",
        "  for datas in data_by_age_category:\n",
        "    epoch_data += shuffle_array(datas)[0:max_per_category]\n",
        "    \n",
        "  return epoch_data\n",
        "  \n",
        "data_loader = DataLoader(get_epoch_data, start_epoch = start_epoch, image_augmentor = image_augmentor)\n",
        "net.init_trainable_weights()\n",
        "#net.load_weights('./feature_extractor_dense_mobilenet_4_4_augmented4')\n",
        "\n",
        "X = tf.placeholder(tf.float32, [batch_size, image_size, image_size, 3])\n",
        "AGE = tf.placeholder(tf.float32, [batch_size])\n",
        "GENDER_ONE_HOT = tf.placeholder(tf.float32, [batch_size, 2])\n",
        "GENDER_MASK = tf.placeholder(tf.float32, [batch_size])\n",
        "age_op, gender_op = net.forward(X)\n",
        "age_loss_op = tf.losses.absolute_difference(AGE, age_op)\n",
        "gender_loss_op = tf.losses.softmax_cross_entropy(GENDER_ONE_HOT, gender_op, weights=GENDER_MASK)\n",
        "gender_loss_weight = 1.0\n",
        "joint_loss_op = age_loss_op + (gender_loss_weight * gender_loss_op)\n",
        "train_op = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(joint_loss_op)\n",
        "\n",
        "saver = tf.train.Saver(max_to_keep = None)\n",
        "  \n",
        "print(len(data_loader.buffered_data))\n",
        "log_file = open('./log.txt', 'w')\n",
        "\n",
        "def train(sess):\n",
        "  total_loss = 0\n",
        "  total_age_loss = 0\n",
        "  total_gender_loss = 0\n",
        "  total_gender_correct_pred = 0\n",
        "  num_gender_labels = 0\n",
        "  iteration_count = 0\n",
        "  pred_count = 0\n",
        "  ts_epoch = time.time()\n",
        "  \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  if (start_epoch != 0):\n",
        "    checkpoint = get_checkpoint(start_epoch - 1)\n",
        "    saver.restore(sess, checkpoint)\n",
        "    print('done restoring session')\n",
        "\n",
        "  while data_loader.epoch <= end_epoch:\n",
        "    epoch = data_loader.epoch\n",
        "    current_idx = data_loader.current_idx\n",
        "    end_idx = data_loader.get_end_idx()\n",
        "\n",
        "    ts = time.time()\n",
        "\n",
        "    batch_x, batch_y = data_loader.next_batch(batch_size, image_size)\n",
        "    batch_age = []\n",
        "    batch_gender_one_hot = []\n",
        "    batch_gender_mask = []\n",
        "    for age_label, gender_label in batch_y:\n",
        "      has_gender_label = gender_label is not None\n",
        "      batch_age.append(age_label)\n",
        "      batch_gender_one_hot.append(get_gender_one_hot(gender_label) if has_gender_label else [0, 0])\n",
        "      batch_gender_mask.append(1.0 if has_gender_label else 0.0)\n",
        "      num_gender_labels += (1.0 if has_gender_label else 0.0)\n",
        "      \n",
        "    age_loss, gender_loss, loss, gender, _ = sess.run([age_loss_op, gender_loss_op, joint_loss_op, gender_op, train_op], feed_dict = { X: batch_x, AGE: batch_age, GENDER_ONE_HOT: batch_gender_one_hot, GENDER_MASK: batch_gender_mask })\n",
        "\n",
        "    total_loss += loss\n",
        "    total_age_loss += age_loss\n",
        "    total_gender_loss += gender_loss\n",
        "    iteration_count += 1\n",
        "    \n",
        "    for batch_idx, pred_gender in enumerate(gender):\n",
        "      pred_gender = gender_code_to_label(np.argmax(pred_gender))\n",
        "      true_gender = gender_code_to_label(np.argmax(batch_gender_one_hot[batch_idx]))\n",
        "      if batch_gender_mask[batch_idx] == 1.0 and pred_gender == true_gender:\n",
        "        total_gender_correct_pred += 1.0\n",
        "\n",
        "    log_file.write(\"epoch \" + str(epoch) + \", (\" + str(current_idx) + \" of \" + str(end_idx) + \"), loss= \" + \"{:.4f}\".format(loss) \n",
        "          + \", time= \" + str((time.time() - ts) * 1000) + \"ms \\n\")\n",
        "\n",
        "    if epoch != data_loader.epoch:\n",
        "      avg_loss = total_loss / iteration_count\n",
        "      avg_age_loss = total_age_loss / iteration_count\n",
        "      avg_gender_loss = total_gender_loss / iteration_count\n",
        "      avg_gender_accuracy = total_gender_correct_pred / num_gender_labels\n",
        "      print('next epoch: ' + str(data_loader.epoch))\n",
        "      print(\"avg_loss= {:.4f}\".format(avg_loss))\n",
        "      print(\"avg_age_loss= {:.4f}\".format(avg_age_loss))\n",
        "      print(\"avg_gender_loss= {:.4f}\".format(avg_gender_loss))\n",
        "      print(\"avg_gender_accuracy= {:.4f}\".format(avg_gender_accuracy))\n",
        "      saver.save(sess, model_name + '.ckpt', global_step = epoch)\n",
        "      epoch_txt_file_path = 'epoch_' + str(epoch) + '.txt'\n",
        "      epoch_txt = open(epoch_txt_file_path, 'w')\n",
        "      epoch_txt.write(\"total_loss= {:.4f}\\n\".format(total_loss))\n",
        "      epoch_txt.write(\"avg_loss= {:.4f}\\n\".format(avg_loss))\n",
        "      epoch_txt.write(\"avg_age_loss= {:.4f}\\n\".format(avg_age_loss))\n",
        "      epoch_txt.write(\"avg_gender_loss= {:.4f}\\n\".format(avg_gender_loss))\n",
        "      epoch_txt.write(\"avg_gender_accuracy= {:.4f}\\n\".format(avg_gender_accuracy))\n",
        "      epoch_txt.write(\"learning_rate= {}\\n\".format(learning_rate))\n",
        "      epoch_txt.write(\"batch_size= {}\\n\".format(batch_size))\n",
        "      epoch_txt.write(\"epoch_time= {}\\n\".format(time.time() - ts_epoch))\n",
        "      epoch_txt.close()\n",
        "\n",
        "      total_loss = 0\n",
        "      total_age_loss = 0\n",
        "      total_gender_loss = 0\n",
        "      total_gender_correct_pred = 0\n",
        "      \n",
        "      num_gender_labels = 0\n",
        "      iteration_count = 0        \n",
        "      ts_epoch = time.time()\n",
        "        \n",
        "  print('done!')\n",
        "  log_file.close() \n",
        "    \n",
        "gpu_session(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71292\n",
            "INFO:tensorflow:Restoring parameters from age_gender_xception_tiny_augmented4_blocks2_5_5000_rgb.ckpt-163\n",
            "done restoring session\n",
            "next epoch: 165\n",
            "avg_loss= 4.4457\n",
            "avg_age_loss= 4.2168\n",
            "avg_gender_loss= 0.2289\n",
            "avg_gender_accuracy= 0.9166\n",
            "INFO:tensorflow:age_gender_xception_tiny_augmented4_blocks2_5_5000_rgb.ckpt-164 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "next epoch: 166\n",
            "avg_loss= 4.4475\n",
            "avg_age_loss= 4.2263\n",
            "avg_gender_loss= 0.2212\n",
            "avg_gender_accuracy= 0.9197\n",
            "INFO:tensorflow:age_gender_xception_tiny_augmented4_blocks2_5_5000_rgb.ckpt-165 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "next epoch: 167\n",
            "avg_loss= 4.4639\n",
            "avg_age_loss= 4.2387\n",
            "avg_gender_loss= 0.2252\n",
            "avg_gender_accuracy= 0.9200\n",
            "INFO:tensorflow:age_gender_xception_tiny_augmented4_blocks2_5_5000_rgb.ckpt-166 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "next epoch: 168\n",
            "avg_loss= 4.4406\n",
            "avg_age_loss= 4.2141\n",
            "avg_gender_loss= 0.2265\n",
            "avg_gender_accuracy= 0.9177\n",
            "INFO:tensorflow:age_gender_xception_tiny_augmented4_blocks2_5_5000_rgb.ckpt-167 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "next epoch: 169\n",
            "avg_loss= 4.4632\n",
            "avg_age_loss= 4.2363\n",
            "avg_gender_loss= 0.2268\n",
            "avg_gender_accuracy= 0.9172\n",
            "INFO:tensorflow:age_gender_xception_tiny_augmented4_blocks2_5_5000_rgb.ckpt-168 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "next epoch: 170\n",
            "avg_loss= 4.4586\n",
            "avg_age_loss= 4.2371\n",
            "avg_gender_loss= 0.2215\n",
            "avg_gender_accuracy= 0.9218\n",
            "INFO:tensorflow:age_gender_xception_tiny_augmented4_blocks2_5_5000_rgb.ckpt-169 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "next epoch: 171\n",
            "avg_loss= 4.4444\n",
            "avg_age_loss= 4.2230\n",
            "avg_gender_loss= 0.2214\n",
            "avg_gender_accuracy= 0.9175\n",
            "INFO:tensorflow:age_gender_xception_tiny_augmented4_blocks2_5_5000_rgb.ckpt-170 is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDQqQSTTbodd",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pjGurZAGlNNN"
      },
      "source": [
        "## Forward Age Range Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IoXvvoS8lNNP",
        "colab": {}
      },
      "source": [
        "from colabsnippets.nn import XceptionTiny\n",
        "from colabsnippets.utils import forward_factory\n",
        "\n",
        "# inputs\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "min_age = 0\n",
        "max_age = 150\n",
        "delta = 0\n",
        "net = AgeGenderXceptionTiny(num_blocks = 2)\n",
        "model_name = net.name + '_augmented4_blocks2_5_5000_rgb'\n",
        "#net = Xception(num_blocks = 2)\n",
        "#model_name = net.name + '_augmented4_tiny_blocks2'\n",
        "\n",
        "predict_age = lambda X: net.forward(X)\n",
        "transform_label = lambda labels: labels\n",
        "transform_prediction = lambda pred_age, pred_gender: (pred_age, gender_code_to_label(np.argmax(pred_gender)))\n",
        "\n",
        "start_epoch = 163\n",
        "end_epoch = 163\n",
        "\n",
        "batch_size = 32\n",
        "image_size = 112\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "dbs = ['utk', 'fgnet', 'chalearn', 'wiki', 'cacd', 'imdb', 'megaage', 'megaage-asian']\n",
        "test_data = filter_data_in_age_range(load_json('./data/testData.json'), min_age - delta, max_age + delta)\n",
        "\n",
        "forward_dbs = forward_dbs_factory(test_data, dbs = dbs, transform_label = transform_label, transform_prediction = transform_prediction)\n",
        "\n",
        "for epoch in range(start_epoch, end_epoch - 1, -1):\n",
        "  print(epoch)\n",
        "  tf.reset_default_graph()\n",
        "  net.init_trainable_weights()\n",
        "\n",
        "  forward = forward_factory(predict_age, batch_size, image_size)\n",
        "  saver = tf.train.Saver(max_to_keep = None)\n",
        "\n",
        "  def test(sess):\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver.restore(sess, get_checkpoint(epoch))\n",
        "    return forward_dbs(lambda batch_x: forward(sess, batch_x))\n",
        "\n",
        "  results = gpu_session(test)\n",
        "  np.save(model_name + '_test_epoch_' + str(epoch) + '.pkl', results)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UBPLhRSQj6I",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwpfcwUrQmV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inputs\n",
        "# ------------------------------------------------------------------\n",
        "net = AgeGenderXceptionTiny(num_blocks = 2)\n",
        "model_name = net.name + '_augmented4_blocks2_5_5000_rgb'\n",
        "#net = Xception(num_blocks = 2)\n",
        "#model_name = net.name + '_augmented4_tiny_blocks2'\n",
        "start_epoch = 163\n",
        "end_epoch = 0\n",
        "min_age = 0\n",
        "max_age = 80\n",
        "\n",
        "compute_loss = lambda y, x: abs(y - x)\n",
        "#compute_loss = lambda y, x: 1 if abs(y - x) < 1 else 0\n",
        "\n",
        "#get_test_result_file_name = lambda epoch: 'dense_mobilenet_4_4_augmented4_test_epoch_132.npy'\n",
        "#get_test_result_file_name = lambda epoch: 'dense_mobilenet_4_4_augmented4_test_epoch_132.npy'\n",
        "#get_test_result_file_name = lambda epoch: 'age_category_classifier_augmented4_test_epoch_51.npy'\n",
        "#get_test_result_file_name = lambda epoch: 'age_category_classifier_lg_augmented4_test_epoch_94.npy'\n",
        "get_test_result_file_name = lambda epoch: model_name + '_test_epoch_' + str(epoch) + '.pkl.npy'\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def extract_hist_results(results, category_range, target_db = None):\n",
        "  num_bins = int((max_age - min_age) / category_range)\n",
        "  counts = np.zeros(num_bins)\n",
        "  acc_hist = np.zeros(num_bins)\n",
        "  \n",
        "  num_gender_preds = np.zeros(num_bins)\n",
        "  num_correct_gender_preds = np.zeros(num_bins)\n",
        "  \n",
        "  for result in results:\n",
        "    db, labels, predictions = result\n",
        "    pred_age, pred_gender = predictions\n",
        "    true_age, true_gender = labels\n",
        "    true_age, pred_age = float(true_age), float(pred_age)\n",
        "    \n",
        "    if (true_age < min_age or true_age >= max_age):\n",
        "      continue\n",
        "    \n",
        "    if target_db is not None and db != target_db:\n",
        "      continue\n",
        "\n",
        "    err = abs(true_age - pred_age)\n",
        "    hist_bin = int(math.floor((true_age - min_age) / category_range))\n",
        "    counts[hist_bin] += 1\n",
        "    acc_hist[hist_bin] += err\n",
        "    \n",
        "    if true_gender is not None:\n",
        "      num_gender_preds[hist_bin] += 1\n",
        "      num_correct_gender_preds[hist_bin] += (1 if true_gender == pred_gender else 0)\n",
        "\n",
        "  for i in range(0, len(counts)):\n",
        "    if counts[i] == 0:\n",
        "      counts[i] = 1\n",
        "    if num_gender_preds[i] == 0:\n",
        "      num_gender_preds[i] = 1\n",
        "    \n",
        "  category_maes = np.divide(acc_hist, counts)\n",
        "  avg_category_maes = category_maes.sum() / num_bins\n",
        "  category_gender_accuracy = np.divide(num_correct_gender_preds, num_gender_preds)\n",
        "  gender_accuracy = category_gender_accuracy.sum() / num_bins\n",
        "  \n",
        "  upper = 1.4\n",
        "  lower = 0.8\n",
        "  \n",
        "  weighted_category_maes = (category_maes * np.arange(upper, lower, -((upper - lower) / num_bins) )).sum() / num_bins\n",
        "  mae = acc_hist.sum() / counts.sum()\n",
        "  return mae, category_maes, avg_category_maes, weighted_category_maes, category_gender_accuracy, gender_accuracy\n",
        "\n",
        "def evaluate_model_results(file):\n",
        "  results = np.load(file, allow_pickle=True)\n",
        "  dbs_data_count = {}\n",
        "\n",
        "  for result in results:\n",
        "    db, labels, predictions = result\n",
        "    pred_age, pred_gender = predictions\n",
        "    true_age, true_gender = labels\n",
        "    true_age, pred_age = float(true_age), float(pred_age)\n",
        "    true_age, pred_age = float(true_age), float(pred_age)\n",
        "    if (true_age < min_age or true_age > max_age):\n",
        "      continue\n",
        "    \n",
        "    if not db in dbs_data_count:\n",
        "      dbs_data_count[db] = 0\n",
        "    dbs_data_count[db] += 1\n",
        "      \n",
        "  data_count = 0\n",
        "  for db in dbs_data_count.keys():\n",
        "    db_data_count = dbs_data_count[db]\n",
        "    data_count += db_data_count\n",
        "    mae, category_maes, avg_category_maes, weighted_category_maes, category_gender_accuracy, gender_accuracy = extract_hist_results(results, 5, db)\n",
        "    print(db + ' : ' + \"mae: {:.4f}\".format(mae) + \", gender accuracy:  {:.4f}\".format(gender_accuracy) + ', ' +  str(db_data_count))\n",
        "    #print(db + ' : ' + \"{:.4f}\".format(mae) + ', '+ \"{:.4f}\".format(avg_category_maes) + ', ' +  str(category_maes) + ', ' +  str(db_data_count))\n",
        "     \n",
        "  mae, category_maes, avg_category_maes, weighted_category_maes, category_gender_accuracy, gender_accuracy = extract_hist_results(results, 5)\n",
        "  print('gender accuracy: ' + \"{:.4f}\".format(gender_accuracy))\n",
        "  print('weighted cat mae: ' + \"{:.4f}\".format(weighted_category_maes))\n",
        "  print('avg cat mae: ' + \"{:.4f}\".format(avg_category_maes))\n",
        "  print('mae: ' + \"{:.4f}\".format(mae))\n",
        "  print(''.join(\"{:.2f} | \".format(v) for v in category_maes))\n",
        "  print(''.join(\"{:.2f} | \".format(v) for v in category_gender_accuracy))\n",
        "\n",
        "for epoch in range(start_epoch, end_epoch - 1, -1):\n",
        "  print(epoch)\n",
        "  evaluate_model_results(get_test_result_file_name(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCYEzaO10Os_",
        "colab_type": "text"
      },
      "source": [
        "## Plot Confusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5OsVdvP0QGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file = 'xception_tiny_augmented4_blocks2_5_5000_test_epoch_57.npy'\n",
        "results = np.load(file)\n",
        "\n",
        "min_age = 0\n",
        "max_age = 150\n",
        "\n",
        "def extract_results(target_db = None):\n",
        "  x, y = [], []\n",
        "  for result in results:\n",
        "    db, true_age, pred_age = result\n",
        "    true_age, pred_age = float(true_age), float(pred_age)\n",
        "    \n",
        "    if (true_age < min_age or true_age > max_age):\n",
        "      continue\n",
        "    \n",
        "    if target_db is not None and db != target_db:\n",
        "      continue\n",
        "\n",
        "    x.append(round(pred_age))\n",
        "    y.append(round(true_age))\n",
        "    \n",
        "  return x, y\n",
        "\n",
        "\n",
        "x_utk, y_utk = extract_results('utk')\n",
        "x_chalearn, y_chalearn = extract_results('chalearn')\n",
        "x_fgnet, y_fgnet = extract_results('fgnet')\n",
        "x_wiki, y_wiki = extract_results('wiki')\n",
        "x_megaage, y_megaage = extract_results('megaage')\n",
        "x_megaage_asian, y_megaage_asian = extract_results('megaage-asian')\n",
        "x_all, y_all = extract_results()\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.xticks(np.arange(-10, 120, 10))\n",
        "plt.yticks(np.arange(-10, 120, 10))\n",
        "plt.scatter(x_all, y_all, s = 5,  c = 'b')\n",
        "plt.show()\n",
        "plt.scatter(x_utk, y_utk, s = 5,  c = 'r')\n",
        "plt.show()\n",
        "plt.scatter(x_chalearn, y_chalearn, s = 5,  c = 'g')\n",
        "plt.show()\n",
        "plt.scatter(x_fgnet, y_fgnet, s = 5,  c = 'y')\n",
        "plt.show()\n",
        "plt.scatter(x_wiki, y_wiki, s = 5,  c = 'b')\n",
        "plt.show()\n",
        "plt.scatter(x_megaage, y_megaage, s = 5,  c = 'r')\n",
        "plt.show()\n",
        "plt.scatter(x_megaage_asian, y_megaage_asian, s = 5,  c = 'y')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGhGVBBSFDiP",
        "colab_type": "text"
      },
      "source": [
        "## Plot MAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmBFeWneFGC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file = 'xception_tiny_augmented4_blocks2_5_5000_test_epoch_56.npy'\n",
        "results = np.load(file)\n",
        "\n",
        "min_age = 0\n",
        "max_age = 80\n",
        "\n",
        "cat_range = 2\n",
        "num_bins = int((max_age - min_age) / cat_range)\n",
        "\n",
        "def extract_results(target_db = None):\n",
        "  \n",
        "  counts = np.ones(num_bins)\n",
        "  acc_hist = np.zeros(num_bins)\n",
        "  for result in results:\n",
        "    db, true_age, pred_age = result\n",
        "    true_age, pred_age = float(true_age), float(pred_age)\n",
        "    \n",
        "    if (true_age < min_age or true_age >= max_age):\n",
        "      continue\n",
        "    \n",
        "    if target_db is not None and db != target_db:\n",
        "      continue\n",
        "\n",
        "    err = abs(true_age - pred_age)\n",
        "    hist_bin = int(math.floor(true_age / cat_range))\n",
        "    counts[hist_bin] += 1\n",
        "    acc_hist[hist_bin] += err\n",
        "    \n",
        "  hist = np.divide(acc_hist, counts)\n",
        "  print(target_db, hist.sum() / num_bins, acc_hist.sum() / counts.sum())\n",
        "  return hist\n",
        "  \n",
        "categories = np.arange(num_bins) * cat_range\n",
        "  \n",
        "#plt.show()\n",
        "plt.scatter(categories, extract_results('utk'), c = 'r', s = 10)\n",
        "#plt.show()\n",
        "plt.scatter(categories, extract_results('chalearn'), c = 'g', s = 10)\n",
        "#plt.show()\n",
        "plt.scatter(categories, extract_results('fgnet'), c = 'y', s = 10)\n",
        "plt.scatter(categories, extract_results(), c = 'b', s = 20)\n",
        "plt.show()  \n",
        "#plt.show()\n",
        "plt.scatter(categories, extract_results('megaage'), c = 'r', s = 10)\n",
        "plt.scatter(categories, extract_results('megaage-asian'), c = 'b', s = 10)\n",
        "plt.show()\n",
        "extract_results('wiki')\n",
        "extract_results('imdb')\n",
        "extract_results('cacd')\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fT6sKtTM2Ww",
        "colab_type": "text"
      },
      "source": [
        "## Show Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXDjfSKXM12w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./show_results && mkdir ./show_results\n",
        "\n",
        "\n",
        "from IPython.display import Image, display\n",
        "from colabsnippets.age_gender_recognition import AgeGenderXceptionTiny\n",
        "from colabsnippets.utils import forward_factory, shuffle_array\n",
        "\n",
        "# inputs\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "tf.reset_default_graph()\n",
        "  \n",
        "min_age = 0\n",
        "max_age = 150\n",
        "db = 'utk'\n",
        "num_inputs = 24\n",
        "num_images_per_row = 8\n",
        "\n",
        "epoch = 92\n",
        "batch_size = 1\n",
        "image_size = 112\n",
        "\n",
        "net = AgeGenderXceptionTiny(num_blocks = 2)\n",
        "model_name = net.name + '_augmented4_blocks2_5_5000'\n",
        "net.init_trainable_weights()\n",
        "\n",
        "predict_age_gender = lambda X: net.forward(X)\n",
        "forward = forward_factory(predict_age_gender, batch_size, image_size)\n",
        "saver = tf.train.Saver(max_to_keep = None)\n",
        "\n",
        "\n",
        "all_data = filter_data_in_age_range(load_json('./data/testData.json'), min_age, max_age)\n",
        "db_data = []\n",
        "for data in all_data:\n",
        "  if db is None or data['db'] == db:\n",
        "    db_data.append(data)\n",
        "    \n",
        "data_loader = DataLoader(shuffle_array(db_data)[0: num_inputs], is_test = True)\n",
        "    \n",
        "def run(sess):\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  saver.restore(sess, get_checkpoint(epoch))\n",
        "\n",
        "  all_x, all_true_ages, all_pred_ages, all_pred_genders = [], [], [], []\n",
        "  next_batch = data_loader.next_batch(batch_size, image_size)\n",
        "  while next_batch != None:\n",
        "    batch_x, batch_y = next_batch\n",
        "    pred_ages, pred_genders = forward(sess, batch_x)\n",
        "    for batch_idx in range(0, batch_size):\n",
        "      #all_x.append(batch_x[batch_idx])\n",
        "      all_x.append(cv2.resize(batch_x[batch_idx], (130, 130)))\n",
        "      all_true_ages.append(float(batch_y[batch_idx][0]))\n",
        "      all_pred_ages.append(pred_ages[batch_idx])\n",
        "      pred_gender = np.argmax(pred_genders[batch_idx])\n",
        "      all_pred_genders.append(gender_code_to_label(pred_gender))\n",
        "    next_batch = data_loader.next_batch(1)\n",
        "    \n",
        "  return all_x, all_true_ages, all_pred_ages, all_pred_genders\n",
        "  \n",
        "all_x, all_true_ages, all_pred_ages, all_pred_genders = gpu_session(run)\n",
        "\n",
        "# display\n",
        "file_idx = 0\n",
        "idx = 0\n",
        "while idx < num_inputs:\n",
        "  imgs = all_x[idx : idx + num_images_per_row]\n",
        "  true_ages = all_true_ages[idx : idx + num_images_per_row]\n",
        "  pred_ages = all_pred_ages[idx : idx + num_images_per_row]\n",
        "  pred_genders = all_pred_genders[idx : idx + num_images_per_row]\n",
        "  for i in range(0, len(imgs)):\n",
        "    text = \"{} | {}\".format(round(true_ages[i]), round(pred_ages[i]))\n",
        "    #cv2.putText(imgs[i], text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "    #cv2.putText(imgs[i], pred_genders[i], (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "    \n",
        "    text = \"{} | {}\".format(int(round(pred_ages[i])), pred_genders[i])\n",
        "    cv2.putText(imgs[i], text, (2, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    \n",
        "  merged_img = np.concatenate(imgs, axis = 1)\n",
        "  file = './show_results/' + str(file_idx) + '.jpg'\n",
        "  cv2.imwrite(file, merged_img)\n",
        "  display(Image(file))\n",
        "  \n",
        "  file_idx += 1\n",
        "  idx += num_images_per_row\n",
        "\n",
        "!rm -rf ./show_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4sn1vIdUorT",
        "colab_type": "text"
      },
      "source": [
        "## Save Intermediate Activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLDSJ9sAUrM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./show_results && mkdir ./show_results\n",
        "\n",
        "\n",
        "from IPython.display import Image, display\n",
        "from colabsnippets.age_gender_recognition import AgeGenderXceptionTiny\n",
        "from colabsnippets.utils import forward_factory, shuffle_array, save_weights\n",
        "from colabsnippets.preprocess import resize_preserve_aspect_ratio, pad_to_square\n",
        "from colabsnippets import WeightInitializer\n",
        "\n",
        "# inputs\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "#inputs = [\"70.96_male0.97.png\", \"3.36_male0.51.png\", \"17.42_male0.88.png\", \"21.05_male0.59.png\", \"37.63_female0.5.png\", \"59.39_male0.94.png\"]\n",
        "inputs = [ \"37.63_female0.5_gt.png\", \"37.63_female0.5_p.png\", \"37.63_female0.5_p2.png\"]\n",
        "\n",
        "num_images_per_row = 8\n",
        "\n",
        "epoch = 92\n",
        "batch_size = 1\n",
        "image_size = 112\n",
        "\n",
        "def load_weights(net, checkpoint_file, weight_initializer = tf.keras.initializers.glorot_normal(), bias_initializer = tf.keras.initializers.Zeros()):\n",
        "  checkpoint_data = np.fromfile(checkpoint_file, dtype = 'float32')\n",
        "\n",
        "  idx = 0\n",
        "  data_idx = 0\n",
        "\n",
        "  def initialize_weights_factory(initializer):\n",
        "    def initialize_weights(name, shape):\n",
        "      nonlocal idx, data_idx\n",
        "      size = 1\n",
        "      for val in shape:\n",
        "        size = size * val\n",
        "      initial_value = np.reshape(checkpoint_data[data_idx:data_idx + size], shape)\n",
        "\n",
        "      data_idx += size\n",
        "\n",
        "      var = tf.get_variable(name, initializer = initial_value.astype(np.float32))\n",
        "\n",
        "      idx += 1\n",
        "\n",
        "      return var\n",
        "\n",
        "    return initialize_weights\n",
        "\n",
        "  net.initialize_weights(WeightInitializer(initialize_weights_factory(weight_initializer), initialize_weights_factory(bias_initializer)))\n",
        "\n",
        "def save_weights(var_list, checkpoint_file):\n",
        "  checkpoint_data = np.array([], dtype = 'float32')\n",
        "  meta_data = []\n",
        "  for var in var_list:\n",
        "    meta_data.append({ 'shape': var.get_shape().as_list(), 'name': var.name })\n",
        "    checkpoint_data = np.append(checkpoint_data, var.eval().flatten())\n",
        "\n",
        "  meta_json = open(checkpoint_file + '.json', 'w')\n",
        "  meta_json.write(json.dumps(meta_data))\n",
        "  meta_json.close()\n",
        "  print(checkpoint_data.dtype)\n",
        "  checkpoint_data.tofile(checkpoint_file)\n",
        "\n",
        "net = AgeGenderXceptionTiny(num_blocks = 2)\n",
        "#model_name = net.name + '_augmented4_blocks2_5_5000'\n",
        "#weights = np.fromfile('tmp.weights.npy', dtype = 'float64')\n",
        "#np.save('age_gender.weights2.npy', weights.astype('float32'))\n",
        "#weights = np.fromfile('age_gender.weights', dtype = 'float32')\n",
        "#np.save('age_gender.weights.npy', weights)\n",
        "#net.load_weights('age_gender.weights')\n",
        "load_weights(net, 'tmp.weights')\n",
        "#net.init_trainable_weights()\n",
        "\n",
        "predict_age_gender = lambda X: net.forward(X)\n",
        "\n",
        "# auto recompile ops in case of new batch size\n",
        "X = tf.placeholder(tf.float32, [batch_size, image_size, image_size, 3])\n",
        "forward_op = predict_age_gender(X)\n",
        "\n",
        "def forward(sess, batch_x):\n",
        "  local_X, local_forward_op = X, forward_op\n",
        "  if batch_x.shape[0] != X.shape[0]:\n",
        "    local_X = tf.placeholder(tf.float32, [batch_x.shape[0], image_size, image_size, 3])\n",
        "    local_forward_op = compile_forward_op(local_X)\n",
        "  return sess.run(local_forward_op, feed_dict = { local_X: batch_x })\n",
        "\n",
        "saver = tf.train.Saver(max_to_keep = None)\n",
        "\n",
        "def pad_to_square2(img):\n",
        "  if len(img.shape) == 2:\n",
        "    img = np.expand_dims(img, axis = 2)\n",
        "\n",
        "  height, width, channels = img.shape\n",
        "  max_dim = max(height, width)\n",
        "  square_img = np.zeros([max_dim, max_dim, channels], dtype = img.dtype)\n",
        "  #square_img.fill(255)\n",
        "\n",
        "  dx = math.floor(abs(max_dim - width) / 2)\n",
        "  dy = math.floor(abs(max_dim - height) / 2)\n",
        "  square_img[dy:dy + height,dx:dx + width] = img\n",
        "\n",
        "  return square_img\n",
        "print(tf.get_default_graph().get_operations())\n",
        "def run(sess):\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  #saver.restore(sess, get_checkpoint(epoch))\n",
        "  #save_weights(tf.global_variables(), 'tmp.weights')\n",
        "\n",
        "  \n",
        "  all_x, all_true_ages, all_true_genders, all_pred_ages, all_pred_genders = [], [], [], [], []\n",
        "  \n",
        "  for file in inputs:\n",
        "    img = cv2.imread(file)\n",
        "    true_age, true_gender = file.split('_')[0:2]\n",
        "    all_true_ages.append(float(true_age))\n",
        "    all_true_genders.append(true_gender)\n",
        "    \n",
        "    img = pad_to_square2(resize_preserve_aspect_ratio(img, 112))\n",
        "    #op = tf.get_default_graph().get_operation_by_name('Placeholder')\n",
        "    #print(op)\n",
        "    #out = sess.run(op.outputs[0], feed_dict = { X: np.array([img]) })\n",
        "    #print(out.dtype, out.shape)\n",
        "    #out.tofile('out')\n",
        "    all_x.append(img)\n",
        "    ages, genders = forward(sess, np.array([img]))\n",
        "    gender_probs = tf.nn.softmax(genders[0]).eval()\n",
        "    gender_code = np.argmax(genders[0])\n",
        "    pred_gender = gender_code_to_label(gender_code) + \"{:.2f}\".format(gender_probs[gender_code])\n",
        "    all_pred_ages.append(ages[0])\n",
        "    all_pred_genders.append(pred_gender)\n",
        "    \n",
        "  return all_x, all_true_ages, all_true_ages, all_pred_ages, all_pred_genders\n",
        "  \n",
        "all_x, all_true_ages, all_true_ages, all_pred_ages, all_pred_genders = gpu_session(run)\n",
        "\n",
        "# display\n",
        "file_idx = 0\n",
        "idx = 0\n",
        "while idx < len(all_true_ages):\n",
        "  imgs = all_x[idx : idx + num_images_per_row]\n",
        "  true_ages = all_true_ages[idx : idx + num_images_per_row]\n",
        "  pred_ages = all_pred_ages[idx : idx + num_images_per_row]\n",
        "  pred_genders = all_pred_genders[idx : idx + num_images_per_row]\n",
        "  for i in range(0, len(imgs)):\n",
        "    text = \"{} | {}\".format(round(true_ages[i]), round(pred_ages[i]))\n",
        "    #cv2.putText(imgs[i], text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "    #cv2.putText(imgs[i], pred_genders[i], (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "    \n",
        "    text = \"{} | {}\".format(int(round(pred_ages[i])), pred_genders[i])\n",
        "    cv2.putText(imgs[i], text, (2, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "    \n",
        "  merged_img = np.concatenate(imgs, axis = 1)\n",
        "  file = './show_results/' + str(file_idx) + '.jpg'\n",
        "  cv2.imwrite(file, merged_img)\n",
        "  display(Image(file))\n",
        "  \n",
        "  file_idx += 1\n",
        "  idx += num_images_per_row\n",
        "\n",
        "!rm -rf ./show_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA6ihajR4hfH",
        "colab_type": "text"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuyC2w-y4myt",
        "colab_type": "text"
      },
      "source": [
        "## Check Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1ett0-a4ku_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./check_inputs && mkdir ./check_inputs\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "num_inputs = 50\n",
        "image_size = 112\n",
        "num_images_per_row = 10\n",
        "db = 'megaage-asian'\n",
        "\n",
        "image_augmentor = ImageAugmentor.load('./augmentor_4.json')\n",
        "train_data = load_json('./data/testData.json')\n",
        "\n",
        "db_data = []\n",
        "for data in train_data:\n",
        "  if db is None or data['db'] == db:\n",
        "    db_data.append(data)\n",
        "    \n",
        "data_loader = DataLoader(db_data, start_epoch = 0, image_augmentor = image_augmentor)\n",
        "batch_x, _ = data_loader.next_batch(num_inputs, image_size)\n",
        "\n",
        "file_idx = 0\n",
        "idx = 0\n",
        "while idx < num_inputs:\n",
        "  imgs = batch_x[idx : idx + num_images_per_row]\n",
        "  merged_img = np.concatenate(imgs, axis = 1)\n",
        "  \n",
        "  file = './check_inputs/' + str(file_idx) + '.jpg'\n",
        "  cv2.imwrite(file, merged_img)\n",
        "  display(Image(file))\n",
        "  \n",
        "  file_idx += 1\n",
        "  idx += num_images_per_row\n",
        "\n",
        "!rm -rf ./check_inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHgNUwn6UBX0",
        "colab_type": "text"
      },
      "source": [
        "## Plot Age Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DUgZJgIUA6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from colabsnippets.utils import shuffle_array\n",
        "\n",
        "num_bins = 60\n",
        "\n",
        "train_data = load_json('./data/trainData.json')\n",
        "def get_epoch_data():\n",
        "  age_category_range = 5\n",
        "  max_per_category = 5000\n",
        "  num_bins = int(120 / age_category_range)\n",
        "  data_by_age_category = []\n",
        "  for i in range(0, num_bins):\n",
        "    data_by_age_category.append([])\n",
        "  \n",
        "  for data in train_data:\n",
        "    true_age = extract_data_labels(data)\n",
        "    hist_bin = int(math.floor(true_age / age_category_range))\n",
        "    data_by_age_category[hist_bin].append(data)\n",
        "  \n",
        "  epoch_data = []\n",
        "  for datas in data_by_age_category:\n",
        "    epoch_data += shuffle_array(datas)[0:max_per_category]\n",
        "    \n",
        "  return epoch_data\n",
        "\n",
        "labels = []\n",
        "for data in get_epoch_data():\n",
        "  labels.append(extract_data_labels(data))\n",
        "foo = plt.hist(labels, num_bins, facecolor='green', alpha=0.75)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}