{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_detection_comparison.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justadudewhohacks/ipynbs/blob/master/face_detection_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxSggcBX4RrJ",
        "colab_type": "text"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lJleH-Y4Hcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install git+https://github.com/justadudewhohacks/image_augment.py\n",
        "!pip install git+https://github.com/justadudewhohacks/colabsnippets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRWMhC4AJOnd",
        "colab_type": "text"
      },
      "source": [
        "## mxnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO4A1PFJJOHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc --version\n",
        "!pip install mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zCRdbvelJRFB"
      },
      "source": [
        "## pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lFTqAXEJTY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hof5xhmLh3uf"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vh2ay-TCh3ul",
        "colab": {}
      },
      "source": [
        "from colabsnippets.DataDownloader import DataDownloader\n",
        "\n",
        "data_downloader = DataDownloader(data_dir = './data')\n",
        "\n",
        "data_downloader.download_data({\n",
        "\t\"celeba\" : [\n",
        "    #test data starts at shard 18\n",
        "    { \"images\": \"1C19zO2dlQz4ShGFJH_zEi3ToDOH-Iomp\" },\n",
        "    { \"images\": \"1S5IIoHbNjv3p7PkJ3ItoAeQJODBX597-\" },\n",
        "    { \"images\": \"1e6TUSjz7Zv6LmDP69Yc3lRIufeK3FuAR\" }\n",
        "\t]\n",
        "}, [])\n",
        "data_downloader.drive.CreateFile({ 'id': '1rujtZzpWX5DP7E7HaxgqOPpk0cRb0ajD' }).GetContentFile('./data/celeba/landmarks.json')\n",
        "data_downloader.download_data({\n",
        "\t\"WIDER\" : [\n",
        "    { \"images\": \"1JHmXqGPngDCbM56eYPeqsaCgJC4vgL4m\", \"boxes\": \"1Hd2i-6dnaWIriFK4Hj0CLZnfGtKcKj9L\" }\n",
        "\t]\n",
        "}, ['boxes'])\n",
        "data_downloader.download_data({\n",
        "\t\"FDDB\" : [\n",
        "    { \"images\": \"1C8RpAZYg5nsPCAOLESGFwKxEaHx5V3Ag\", \"boxes\": \"1ACZPuSB7j0c0_hDIBL_MSW4rrzPhC1ab\" }\n",
        "\t]\n",
        "}, ['boxes'])\n",
        "\n",
        "print('done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CAhR3ujg912",
        "colab_type": "text"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZPw0RCag9CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import types\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from augment import ImageAugmentor, augment\n",
        "from augment.augment import abs_coords\n",
        "from colabsnippets.utils import load_json\n",
        "from colabsnippets import BatchLoader\n",
        "\n",
        "'''\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "Data Loader\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "'''\n",
        "celeba_landmarks_by_file = load_json('./data/celeba/landmarks.json')\n",
        "\n",
        "def min_bbox_from_pts(pts):\n",
        "  min_x, min_y, max_x, max_y = 1.0, 1.0, 0, 0\n",
        "  for pt in pts:\n",
        "    x, y = pt\n",
        "    min_x = x if x < min_x else min_x\n",
        "    min_y = y if y < min_y else min_y\n",
        "    max_x = max_x if x < max_x else x\n",
        "    max_y = max_y if y < max_y else y\n",
        "\n",
        "  return [min_x, min_y, max_x, max_y]\n",
        "  \n",
        "def json_boxes_to_array(boxes):\n",
        "  out_boxes = []\n",
        "  for box in boxes:\n",
        "    x, y, w, h = box['x'], box['y'], box['width'], box['height']\n",
        "    out_box = (x, y, w, h)     \n",
        "    if w <= 0 or h <= 0:\n",
        "      raise Exception(\"box has invalid width or height: {}\".format(out_box))   \n",
        "    for val in out_box:\n",
        "      if val < -0.5 or val > 1.5:\n",
        "        raise Exception(\"box is probably not a valid relative box: {}\".format(out_box))\n",
        "    out_boxes.append(out_box)\n",
        "  return out_boxes\n",
        " \n",
        "def extract_data_labels(data):\n",
        "  db = data['db']\n",
        "  img_file = data['file']\n",
        "  if db == 'celeba':\n",
        "    landmarks = celeba_landmarks_by_file[img_file]\n",
        "    x, y, max_x, max_y = min_bbox_from_pts(landmarks)\n",
        "    w, h = max_x - x, max_y - y\n",
        "    padding = 1.5\n",
        "\n",
        "    x = x - (0.5 * padding * w)\n",
        "    y = y - (0.5 * padding * h)\n",
        "    w = w + (padding * w)\n",
        "    h = h + (padding * h)\n",
        "\n",
        "    return [(x, y, w, h)]\n",
        "  if db == 'WIDER' or db == 'FDDB':\n",
        "    boxes_file = img_file.replace('.jpg', '.json')\n",
        "    boxes_dir = \"boxes-shard{}\".format(data['shard']) if 'shard' in data else 'boxes'\n",
        "    boxes_path = \"./data/{}/{}/{}\".format(db, boxes_dir, boxes_file)\n",
        "    boxes = load_json(boxes_path)\n",
        "    return json_boxes_to_array(boxes)\n",
        "  \n",
        "  raise Exception(\"extract_data_labels - unknown db '{}'\".format(db))\n",
        "    \n",
        "    \n",
        "def resolve_image_path(data):\n",
        "  db = data['db']\n",
        "  img_file = data['file']\n",
        "  img_dir = \"images-shard{}\".format(data['shard']) if 'shard' in data else 'images'\n",
        "  img_path = \"./data/{}/{}/{}\".format(db, img_dir, img_file)\n",
        "  return img_path\n",
        "\n",
        "class DataLoader(BatchLoader):\n",
        "  def __init__(self, data):  \n",
        "    BatchLoader.__init__(\n",
        "      self, \n",
        "      data if type(data) is types.FunctionType else lambda: data, \n",
        "      resolve_image_path, \n",
        "      extract_data_labels,\n",
        "      start_epoch = None, \n",
        "      is_test = True\n",
        "    )\n",
        "      \n",
        "  def load_image_and_labels_batch(self, datas, image_size):\n",
        "    batch_x, batch_y = [], []\n",
        "    for data in datas:\n",
        "      image = self.load_image(data)\n",
        "      boxes = self.extract_data_labels(data)\n",
        "      image, boxes = augment(image, boxes = boxes, pad_to_square = True, resize = image_size)\n",
        "      batch_x.append(image)\n",
        "      batch_y.append(boxes)\n",
        "        \n",
        "    return batch_x, batch_y\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyfeUf7n4UwV",
        "colab_type": "text"
      },
      "source": [
        "# Retina Face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDQcWhcg46IC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/deepinsight/insightface\n",
        "!cd ./insightface/RetinaFace && make\n",
        "!wget https://www.dropbox.com/s/53ftnlarhyrpkg2/retinaface-R50.zip -O retinaface-R50.zip\n",
        "!unzip retinaface-R50.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_d6RYg55IBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "import glob\n",
        "import sys\n",
        "sys.path.append('./insightface/RetinaFace')\n",
        "from insightface.RetinaFace.retinaface import RetinaFace\n",
        "\n",
        "def create_retina_face(scales = [1.0], do_flip = False):\n",
        "  detector = RetinaFace('./R50', 0, 0, 'net3')\n",
        "  def detect(img, min_score):\n",
        "    faces, landmarks = detector.detect(img, min_score, scales=scales, do_flip=do_flip)\n",
        "    out_faces = []\n",
        "    img_size = img.shape[0]\n",
        "    if faces is not None:\n",
        "      for face in faces:\n",
        "        x0, y0, x1, y1 = face.astype(np.int)[0:4] / img_size\n",
        "        out_faces.append([x0, y0, x1-x0, y1-y0])\n",
        "    return out_faces\n",
        "  return detect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDyIVMhZhikg",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqtRSKp4zzmu",
        "colab_type": "text"
      },
      "source": [
        "## Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkveU4uBhkRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "\n",
        "dbs = ['celeba', 'fddb', 'wider']\n",
        "min_score = 0.5\n",
        "min_image_size = 128\n",
        "max_image_size =  608\n",
        "detect = create_retina_face(scales = [1.0], do_flip = False)\n",
        "  \n",
        "for db in dbs:\n",
        "  for image_size in range(min_image_size, max_image_size + 1, 32):\n",
        "    print(db, image_size)\n",
        "    out_filename = \"retina_scales_1.0_flip_no_{}_{}\".format(db, image_size)\n",
        "\n",
        "    test_data = load_json(\"./{}_testData.json\".format(db))\n",
        "    data_loader = DataLoader(test_data)\n",
        "    get_next_batch = lambda : data_loader.next_batch(1, image_size)\n",
        "\n",
        "    next_batch = get_next_batch()\n",
        "    results = []\n",
        "    avg_time = 0\n",
        "    while (next_batch != None):\n",
        "      batch_x, batch_gt_boxes = next_batch\n",
        "      gt_boxes = batch_gt_boxes[0]\n",
        "      ts = time()\n",
        "      boxes = detect(batch_x[0], min_score)\n",
        "      avg_time += ((time() - ts) * 1000)\n",
        "      results.append((boxes, gt_boxes))\n",
        "      next_batch = get_next_batch()\n",
        "    avg_time = avg_time / len(results)\n",
        "    print(avg_time)\n",
        "    np.save(out_filename, results, allow_pickle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKt87q9U3i5f",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUBvbZoM3kO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from colabsnippets.face_detection import calculate_iou\n",
        "\n",
        "min_score = 0.5\n",
        "image_size = 128\n",
        "filename = \"retina_celeba_{}.npy\".format(image_size)\n",
        "\n",
        "results = np.load(filename, allow_pickle = True)\n",
        "\n",
        "#TODO NMS\n",
        "\n",
        "true_positives = 0\n",
        "false_positives = 0\n",
        "total_boxes = 0\n",
        "for res in results:\n",
        "  pred_boxes, gt_boxes = res\n",
        "  pred_boxes = np.array(pred_boxes) * image_size\n",
        "  gt_boxes = np.array(gt_boxes) * image_size\n",
        "  total_boxes += len(gt_boxes)\n",
        "\n",
        "\n",
        "  for gt_box in gt_boxes:\n",
        "    is_detected = False\n",
        "    for pred_idx, pred_box in enumerate(pred_boxes):\n",
        "      iou = calculate_iou(pred_box, gt_box)\n",
        "      if iou > 0.5:\n",
        "        is_detected = True\n",
        "      else:\n",
        "        false_positives += 1\n",
        "\n",
        "    if is_detected:\n",
        "      true_positives += 1\n",
        "\n",
        "print(filename)\n",
        "print(\"- true_positives: {}\".format(true_positives))\n",
        "print(\"- false_positives: {}\".format(false_positives))\n",
        "print(\"- true_positives ratio: {}\".format(true_positives / total_boxes))\n",
        "print(\"- false_positives ratio: {}\".format(false_positives / total_boxes))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}