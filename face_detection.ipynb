{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justadudewhohacks/ipynbs/blob/master/face_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeObtjLNxBqx",
        "colab_type": "text"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm3eajF2xAx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install git+https://github.com/justadudewhohacks/image_augment.py\n",
        "!pip install git+https://github.com/justadudewhohacks/colabsnippets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hof5xhmLh3uf"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vh2ay-TCh3ul",
        "colab": {}
      },
      "source": [
        "from colabsnippets.DataDownloader import DataDownloader\n",
        "\n",
        "data_downloader = DataDownloader(data_dir = './data')\n",
        "\n",
        "data_downloader.download_data({\n",
        "\t\"WIDER\" : [\n",
        "    { \"images\": \"1JHmXqGPngDCbM56eYPeqsaCgJC4vgL4m\", \"boxes\": \"1aeAGd5LmL8EBB1yaZxKOp1NbZ1CBJBmm\" }\n",
        "\t]\n",
        "}, ['boxes'])\n",
        "\n",
        "print('done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PXB_uMCpaYG",
        "colab_type": "text"
      },
      "source": [
        "# Common"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH6DheKgpfU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import types\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from augment import ImageAugmentor, augment\n",
        "from augment.augment import abs_coords\n",
        "from colabsnippets.utils import load_json\n",
        "from colabsnippets import BatchLoader\n",
        "\n",
        "'''\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "Data Loader\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "'''\n",
        "  \n",
        "def transform_boxes(boxes):\n",
        "  out_boxes = []\n",
        "  for box in boxes:\n",
        "    out_box = (box['x'], box['y'], box['width'], box['height'])\n",
        "    for val in out_box:\n",
        "      if abs(val) > 1.0:\n",
        "        raise Exception(\"box is probably not a valid relative box: {}\".format(out_box))\n",
        "    out_boxes.append(out_box)\n",
        "  return out_boxes\n",
        "  \n",
        "def extract_data_labels(data):\n",
        "  db = data['db']\n",
        "  img_file = data['file']\n",
        "  boxes_file = img_file.replace('.jpg', '.json')\n",
        "  boxes_dir = \"boxes-shard{}\".format(data['shard']) if 'shard' in data else 'boxes'\n",
        "  boxes_path = \"./data/{}/{}/{}\".format(db, boxes_dir, boxes_file)\n",
        "  boxes = load_json(boxes_path)\n",
        "  return transform_boxes(boxes)\n",
        "    \n",
        "def resolve_image_path(data):\n",
        "  db = data['db']\n",
        "  img_file = data['file']\n",
        "  img_dir = \"images-shard{}\".format(data['shard']) if 'shard' in data else 'images'\n",
        "  img_path = \"./data/{}/{}/{}\".format(db, img_dir, img_file)\n",
        "  return img_path\n",
        "\n",
        "def min_bbox(boxes):\n",
        "  min_x, min_y, max_x, max_y = 1.0, 1.0, 0, 0\n",
        "  for box in boxes:\n",
        "    x, y, w, h = box\n",
        "    pts = [(x, y), (x + w, y + h)]\n",
        "    for x, y in pts:\n",
        "      min_x = x if x < min_x else min_x\n",
        "      min_y = y if y < min_y else min_y\n",
        "      max_x = max_x if x < max_x else x\n",
        "      max_y = max_y if y < max_y else y\n",
        "\n",
        "  return [min_x, min_y, max_x, max_y]\n",
        "\n",
        "class DataLoader(BatchLoader):\n",
        "  def __init__(self, data, image_augmentor = None, start_epoch = None, is_test = False):  \n",
        "    self.image_augmentor = image_augmentor\n",
        "    BatchLoader.__init__(\n",
        "      self, \n",
        "      data if type(data) is types.FunctionType else lambda: data, \n",
        "      resolve_image_path, \n",
        "      extract_data_labels,\n",
        "      start_epoch = start_epoch, \n",
        "      is_test = is_test\n",
        "    )\n",
        "      \n",
        "  def load_image_and_labels_batch(self, datas, image_size):\n",
        "    batch_x, batch_y = [], []\n",
        "    for data in datas:\n",
        "      boxes = self.extract_data_labels(data)\n",
        "      image = self.load_image(data)\n",
        "      roi = min_bbox(boxes)\n",
        "      if self.image_augmentor is not None:\n",
        "        image, boxes = self.image_augmentor.augment(image, boxes = boxes, random_crop = roi, pad_to_square = True, resize = image_size)\n",
        "      else:\n",
        "        image, boxes = augment(image, boxes = boxes, random_crop = roi, pad_to_square = True, resize = image_size)\n",
        "      batch_x.append(image)\n",
        "      batch_y.append(boxes)\n",
        "        \n",
        "    return batch_x, batch_y\n",
        "\n",
        "\n",
        "'''\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "utility\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "def gpu_session(callback):\n",
        "  config = tf.ConfigProto()\n",
        "  config.gpu_options.allow_growth = True\n",
        "  config.allow_soft_placement = True\n",
        "  config.log_device_placement = True\n",
        "  with tf.Session(config = config) as session:\n",
        "    with tf.device('/gpu:0'):\n",
        "      return callback(session)\n",
        "\n",
        "def get_checkpoint(model_name, epoch):\n",
        "  return model_name + '.ckpt-' + str(epoch)\n",
        "\n",
        "def draw_box(img, box):\n",
        "  x, y, w, h = abs_coords(box, img)\n",
        "\n",
        "  cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 1)\n",
        "  cv2.circle(img, (x, y), 2, (0, 0, 255), -1)\n",
        "  cv2.circle(img, (x, y + h), 2, (0, 0, 255), -1)\n",
        "  cv2.circle(img, (x + w, y), 2, (0, 0, 255), -1)\n",
        "  cv2.circle(img, (x + w, y + h), 2, (0, 0, 255), -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1--PqzIsLg27",
        "colab_type": "text"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n29zYuNALlQs",
        "colab_type": "text"
      },
      "source": [
        "## Check Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euit4LNQLfoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./check_inputs && mkdir ./check_inputs\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "num_inputs = 10\n",
        "image_size = 400\n",
        "num_images_per_row = 2\n",
        "db = 'WIDER'\n",
        "\n",
        "image_augmentor = ImageAugmentor.load('./augmentor_4.json')\n",
        "train_data = load_json('./data/trainData.json')\n",
        "\n",
        "db_data = []\n",
        "for data in train_data:\n",
        "  if db is None or data['db'] == db:\n",
        "    db_data.append(data)\n",
        "    \n",
        "data_loader = DataLoader(db_data, start_epoch = 0, image_augmentor = image_augmentor)\n",
        "batch_x, batch_y = data_loader.next_batch(num_inputs, image_size)\n",
        "\n",
        "file_idx = 0\n",
        "idx = 0\n",
        "while idx < num_inputs:\n",
        "  imgs = np.stack(batch_x[idx : idx + num_images_per_row], axis = 0)\n",
        "  all_boxes = batch_y[idx : idx + num_images_per_row]\n",
        "  for i, boxes in enumerate(all_boxes):\n",
        "    for box in boxes:\n",
        "      draw_box(imgs[i], box)\n",
        "  \n",
        "  merged_img = np.concatenate(imgs, axis = 1)\n",
        "  \n",
        "  file = './check_inputs/' + str(file_idx) + '.jpg'\n",
        "  cv2.imwrite(file, merged_img)\n",
        "  display(Image(file))\n",
        "  \n",
        "  file_idx += 1\n",
        "  idx += num_images_per_row\n",
        "\n",
        "!rm -rf ./check_inputs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}