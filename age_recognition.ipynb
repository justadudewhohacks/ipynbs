{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "age_recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "2ZLF_BXtSdtD",
        "NJE8L6bFY-Pn"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justadudewhohacks/ipynbs/blob/master/age_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ht-jSYnkRl3G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dependencies\n"
      ]
    },
    {
      "metadata": {
        "id": "6dwkETQzJjnc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZLF_BXtSdtD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download Data"
      ]
    },
    {
      "metadata": {
        "id": "e6RkL5CMhNjQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "utk_images_7z_id = ''\n",
        "utk_landmarks_7z_id = ''\n",
        "\n",
        "appareal_labels_json_id = ''\n",
        "appareal_images_7z_id = ''\n",
        "appareal_landmarks_7z_id = ''\n",
        "\n",
        "wiki_labels_json_id = ''\n",
        "wiki_images_7z_id = ''\n",
        "wiki_landmarks_7z_id = ''\n",
        "\n",
        "if not os.path.exists('./data'):\n",
        "  os.makedirs('./data')\n",
        "if not os.path.exists('./data/utk'):\n",
        "  os.makedirs('./data/utk')\n",
        "if not os.path.exists('./data/appareal'):\n",
        "  os.makedirs('./data/appareal')\n",
        "if not os.path.exists('./data/wiki'):\n",
        "  os.makedirs('./data/wiki')\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "  \n",
        "print('downloading utk data...')\n",
        "drive.CreateFile({ 'id': utk_images_7z_id }).GetContentFile('./data/utk/images.7z')\n",
        "drive.CreateFile({ 'id': utk_landmarks_7z_id }).GetContentFile('./data/utk/landmarks.7z')\n",
        "\n",
        "print('downloading appareal data...')\n",
        "drive.CreateFile({ 'id': appareal_labels_json_id }).GetContentFile('./data/appareal/labels.json')\n",
        "drive.CreateFile({ 'id': appareal_images_7z_id }).GetContentFile('./data/appareal/images.7z')\n",
        "drive.CreateFile({ 'id': appareal_landmarks_7z_id }).GetContentFile('./data/appareal/landmarks.7z')\n",
        "\n",
        "print('downloading wiki data...')\n",
        "drive.CreateFile({ 'id': wiki_labels_json_id }).GetContentFile('./data/wiki/labels.json')\n",
        "drive.CreateFile({ 'id': wiki_images_7z_id }).GetContentFile('./data/wiki/images.7z')\n",
        "drive.CreateFile({ 'id': wiki_landmarks_7z_id }).GetContentFile('./data/wiki/landmarks.7z')\n",
        "  \n",
        "print('done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJE8L6bFY-Pn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Unzip Data"
      ]
    },
    {
      "metadata": {
        "id": "d1rf140N_pmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd ./data/utk && p7zip -d ./images.7z\n",
        "!cd ./data/utk && p7zip -d ./landmarks.7z\n",
        "!cd ./data/appareal && p7zip -d ./images.7z\n",
        "!cd ./data/appareal && p7zip -d ./landmarks.7z\n",
        "!cd ./data/wiki && p7zip -d ./images.7z\n",
        "!cd ./data/wiki && p7zip -d ./landmarks.7z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nnp9-Jwz5GqM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "cCYJYkAi5Ejn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import json\n",
        "import numpy as np\n",
        "from random import randint\n",
        "\n",
        "def num_in_range(val, min_val, max_val):\n",
        "  return min(max(min_val, val), max_val)\n",
        "\n",
        "def random_crop(img, landmarks):\n",
        "  height, width, _ = img.shape\n",
        "  min_x, min_y, max_x, max_y = width, height, 0, 0\n",
        "  for pt in landmarks:\n",
        "    min_x = pt['x'] if pt['x'] < min_x else min_x\n",
        "    min_y = pt['y'] if pt['y'] < min_y else min_y\n",
        "    max_x = max_x if pt['x'] < max_x else pt['x']\n",
        "    max_y = max_y if pt['y'] < max_y else pt['y']\n",
        "  \n",
        "  min_x = int(num_in_range(min_x, 0, 1) * width)\n",
        "  min_y = int(num_in_range(min_y, 0, 1) * height)\n",
        "  max_x = int(num_in_range(max_x, 0, 1) * width)\n",
        "  max_y = int(num_in_range(max_y, 0, 1) * height)\n",
        "  x0 = randint(0, min_x)\n",
        "  y0 = randint(0, min_y)\n",
        "  x1 = randint(0, abs(width - max_x)) + max_x\n",
        "  y1 = randint(0, abs(height - max_y)) + max_y\n",
        "\n",
        "  return img[y0:y1, x0:x1]\n",
        "\n",
        "def resize_preserve_aspect_ratio(img, size):\n",
        "  height, width, _ = img.shape\n",
        "  max_dim = max(height, width)\n",
        "  ratio = size / float(max_dim)\n",
        "  shape = (height * ratio, width * ratio)\n",
        "  resized_img = cv2.resize(img, (int(round(height * ratio)), int(round(width * ratio))))\n",
        "  \n",
        "  return resized_img\n",
        "  \n",
        "def pad_to_square(img):\n",
        "  height, width, channels = img.shape\n",
        "  max_dim = max(height, width)\n",
        "  square_img = np.zeros([max_dim, max_dim, channels])\n",
        "\n",
        "  dx = math.floor(abs(max_dim - width) / 2)\n",
        "  dy = math.floor(abs(max_dim - height) / 2)\n",
        "  square_img[dy:dy + height,dx:dx + width] = img\n",
        "\n",
        "  return square_img\n",
        "\n",
        "def preprocess(img, landmarks, size):\n",
        "  cropped_img = random_crop(img, landmarks)\n",
        "  resized_img = resize_preserve_aspect_ratio(cropped_img, size)\n",
        "  square_img = pad_to_square(resized_img)\n",
        "  \n",
        "  return square_img\n",
        "\n",
        "def load_batch(datas):\n",
        "  preprocessed_imgs = []\n",
        "  \n",
        "  for data in datas:\n",
        "    db = data['db']\n",
        "    img_file = data['file']\n",
        "    file_suffix = 'chip_0' if db == 'utk' else ('face_0' if db == 'appareal' else '')\n",
        "    landmarks_file = img_file.replace(file_suffix + '.jpg', file_suffix + '.json')\n",
        "    img_file_path = './data/' + db + '/cropped-images/' + img_file\n",
        "    landmarks_file_path = './data/' + db + '/landmarks/' + landmarks_file\n",
        "    \n",
        "    img = cv2.imread(img_file_path)\n",
        "    with open(landmarks_file_path) as json_file:  \n",
        "      landmarks = json.load(json_file)\n",
        "      preprocessed_img = preprocess(img, landmarks, 112)\n",
        "      preprocessed_imgs.append(preprocessed_img)\n",
        "      \n",
        "  return np.stack(preprocessed_imgs, axis=0)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xj5k6dBZj08I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "lbICGURqj2ip",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}