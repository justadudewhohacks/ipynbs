{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extract_weights.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justadudewhohacks/ipynbs/blob/master/extract_weights_mnet_260_640_80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxSggcBX4RrJ",
        "colab_type": "text"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lJleH-Y4Hcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df49e66d-bebb-4bf2-dc5e-cdb5f053d01a"
      },
      "source": [
        "#!pip uninstall numpy -y\n",
        "#!pip install numpy==1.14.5\n",
        "!pip install numpy\n",
        "!pip install -U -q PyDrive\n",
        "!pip install git+https://github.com/justadudewhohacks/image_augment.py\n",
        "!pip install git+https://github.com/justadudewhohacks/colabsnippets\n",
        "!pip install albumentations==0.3.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.4)\n",
            "Collecting git+https://github.com/justadudewhohacks/image_augment.py\n",
            "  Cloning https://github.com/justadudewhohacks/image_augment.py to /tmp/pip-req-build-vju9x81i\n",
            "  Running command git clone -q https://github.com/justadudewhohacks/image_augment.py /tmp/pip-req-build-vju9x81i\n",
            "Building wheels for collected packages: augment\n",
            "  Building wheel for augment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for augment: filename=augment-0.0.5-cp36-none-any.whl size=4879 sha256=c1d9b761d6d3d04e74a00bc3020a1cae6951fd3c6e9f982abe4b2436514d5934\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i2a27iml/wheels/6f/f7/4a/e8e6dc3a68ae11e9b1f6872c5c1be9bed2052f05e487df549f\n",
            "Successfully built augment\n",
            "Installing collected packages: augment\n",
            "Successfully installed augment-0.0.5\n",
            "Collecting git+https://github.com/justadudewhohacks/colabsnippets\n",
            "  Cloning https://github.com/justadudewhohacks/colabsnippets to /tmp/pip-req-build-d28x7c6w\n",
            "  Running command git clone -q https://github.com/justadudewhohacks/colabsnippets /tmp/pip-req-build-d28x7c6w\n",
            "Building wheels for collected packages: colabsnippets\n",
            "  Building wheel for colabsnippets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colabsnippets: filename=colabsnippets-0.0.114-cp36-none-any.whl size=73195 sha256=2c082920d88bf444c0ec6eb91a2a508a82400ea65f752340814f5057229e0547\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_oi797t1/wheels/a4/f3/4d/514be480c5a7dfea589012f45748e962bfe3563921114afb96\n",
            "Successfully built colabsnippets\n",
            "Installing collected packages: colabsnippets\n",
            "Successfully installed colabsnippets-0.0.114\n",
            "Collecting albumentations==0.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/36/2b95494205a81d791ec891d5d538cd645b5f6ce22f64ffd20a7412fe02e1/albumentations-0.3.3.tar.gz (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.3.3) (1.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.3.3) (1.4.1)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 23.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.3.3) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.3.3) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (1.12.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (3.2.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (7.0.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.3) (4.4.2)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.3.3-cp36-none-any.whl size=55380 sha256=aa7c4338e32c127b82222c574b325235e95ae6e8de84554dc365f23f8f8b1153\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/67/12/fe5e79caf7aa6bbdca1506fc66bfd61fc4eae5abb5397b9c08\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=26e16a57c7b7d62be324974b1e665e3a22a4654576e4f430ff865c005ee23a82\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.3.3 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vReIIqCndSUU",
        "colab_type": "text"
      },
      "source": [
        "# ULFGFD+\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfzN39kteHsr",
        "colab_type": "code",
        "outputId": "83127e2b-0558-48ca-a3f4-3a2b9a1652ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/biubug6/Face-Detector-1MB-with-landmark/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Face-Detector-1MB-with-landmark'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "Receiving objects:   0% (1/129)   \rReceiving objects:   1% (2/129)   \rReceiving objects:   2% (3/129)   \rReceiving objects:   3% (4/129)   \rReceiving objects:   4% (6/129)   \rReceiving objects:   5% (7/129)   \rReceiving objects:   6% (8/129)   \rReceiving objects:   7% (10/129)   \rReceiving objects:   8% (11/129)   \rReceiving objects:   9% (12/129)   \rReceiving objects:  10% (13/129)   \rReceiving objects:  11% (15/129)   \rReceiving objects:  12% (16/129)   \rReceiving objects:  13% (17/129)   \rReceiving objects:  14% (19/129)   \rReceiving objects:  15% (20/129)   \rReceiving objects:  16% (21/129)   \rReceiving objects:  17% (22/129)   \rReceiving objects:  18% (24/129)   \rReceiving objects:  19% (25/129)   \rReceiving objects:  20% (26/129)   \rReceiving objects:  21% (28/129)   \rReceiving objects:  22% (29/129)   \rReceiving objects:  23% (30/129)   \rReceiving objects:  24% (31/129)   \rReceiving objects:  25% (33/129)   \rReceiving objects:  26% (34/129)   \rReceiving objects:  27% (35/129)   \rReceiving objects:  28% (37/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  29% (38/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  30% (39/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  31% (40/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  32% (42/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  33% (43/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  34% (44/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  35% (46/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  36% (47/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  37% (48/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  38% (50/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  39% (51/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  40% (52/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  41% (53/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  42% (55/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  43% (56/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  44% (57/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  45% (59/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  46% (60/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  47% (61/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  48% (62/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  49% (64/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  50% (65/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  51% (66/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  52% (68/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  53% (69/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  54% (70/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  55% (71/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  56% (73/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  57% (74/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  58% (75/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  59% (77/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  60% (78/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  61% (79/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  62% (80/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  63% (82/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  64% (83/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  65% (84/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  66% (86/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  67% (87/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  68% (88/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  69% (90/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  70% (91/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  71% (92/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  72% (93/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  73% (95/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  74% (96/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  75% (97/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  76% (99/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  77% (100/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  78% (101/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  79% (102/129), 1.68 MiB | 3.30 MiB/s   \rremote: Total 129 (delta 0), reused 0 (delta 0), pack-reused 129\u001b[K\n",
            "Receiving objects:  80% (104/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  81% (105/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  82% (106/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  83% (108/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  84% (109/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  85% (110/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  86% (111/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  87% (113/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  88% (114/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  89% (115/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  90% (117/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  91% (118/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  92% (119/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  93% (120/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  94% (122/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  95% (123/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  96% (124/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  97% (126/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  98% (127/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects:  99% (128/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects: 100% (129/129), 1.68 MiB | 3.30 MiB/s   \rReceiving objects: 100% (129/129), 7.87 MiB | 10.53 MiB/s, done.\n",
            "Resolving deltas:   0% (0/32)   \rResolving deltas:   9% (3/32)   \rResolving deltas:  15% (5/32)   \rResolving deltas:  21% (7/32)   \rResolving deltas:  25% (8/32)   \rResolving deltas:  31% (10/32)   \rResolving deltas:  37% (12/32)   \rResolving deltas:  43% (14/32)   \rResolving deltas:  50% (16/32)   \rResolving deltas:  53% (17/32)   \rResolving deltas:  56% (18/32)   \rResolving deltas:  59% (19/32)   \rResolving deltas:  62% (20/32)   \rResolving deltas:  90% (29/32)   \rResolving deltas: 100% (32/32)   \rResolving deltas: 100% (32/32), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcaMR7aCeN1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/Face-Detector-1MB-with-landmark')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z84U-q4y34fo",
        "colab": {}
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls-o6X9Ud_wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import time\n",
        "from data import cfg_mnet, cfg_slim, cfg_rfb\n",
        "from layers.functions.prior_box import PriorBox\n",
        "from utils.nms.py_cpu_nms import py_cpu_nms\n",
        "import cv2\n",
        "\n",
        "from models.retinaface import RetinaFace\n",
        "from models.net_slim import Slim\n",
        "from models.net_rfb import RFB\n",
        "from utils.box_utils import decode, decode_landm\n",
        "from utils.timer import Timer\n",
        "\n",
        "def check_keys(model, pretrained_state_dict):\n",
        "    ckpt_keys = set(pretrained_state_dict.keys())\n",
        "    model_keys = set(model.state_dict().keys())\n",
        "    used_pretrained_keys = model_keys & ckpt_keys\n",
        "    unused_pretrained_keys = ckpt_keys - model_keys\n",
        "    missing_keys = model_keys - ckpt_keys\n",
        "    print('Missing keys:{}'.format(len(missing_keys)))\n",
        "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
        "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
        "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
        "    return True\n",
        "\n",
        "\n",
        "def remove_prefix(state_dict, prefix):\n",
        "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
        "    print('remove prefix \\'{}\\''.format(prefix))\n",
        "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
        "    return {f(key): value for key, value in state_dict.items()}\n",
        "\n",
        "\n",
        "def load_model(model, pretrained_path, load_to_cpu):\n",
        "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
        "    if load_to_cpu:\n",
        "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
        "    else:\n",
        "        device = torch.cuda.current_device()\n",
        "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
        "    if \"state_dict\" in pretrained_dict.keys():\n",
        "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
        "    else:\n",
        "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
        "    check_keys(model, pretrained_dict)\n",
        "    model.load_state_dict(pretrained_dict, strict=False)\n",
        "    return model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models.detection.backbone_utils as backbone_utils\n",
        "import torchvision.models._utils as _utils\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "def conv_bn(inp, oup, stride = 1):\n",
        "  return nn.Sequential(\n",
        "    nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "    nn.BatchNorm2d(oup),\n",
        "    nn.ReLU(inplace=True)\n",
        "  )\n",
        "\n",
        "def depth_conv2d(inp, oup, kernel=1, stride=1, pad=0):\n",
        "  return nn.Sequential(\n",
        "    nn.Conv2d(inp, inp, kernel_size = kernel, stride = stride, padding=pad, groups=inp),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(inp, oup, kernel_size=1)\n",
        "  )\n",
        "\n",
        "def conv_dw(inp, oup, stride):\n",
        "  return nn.Sequential(\n",
        "    nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
        "    nn.BatchNorm2d(inp),\n",
        "    nn.ReLU(inplace=True),\n",
        "\n",
        "    nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
        "    nn.BatchNorm2d(oup),\n",
        "    nn.ReLU(inplace=True)\n",
        "  )\n",
        "\n",
        "def conv_bn1X1(inp, oup, stride):\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(inp, oup, 1, stride, padding=0, bias=False),\n",
        "      nn.BatchNorm2d(oup),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "\n",
        "class FPN5(nn.Module):\n",
        "  def __init__(self,in_channels_list,out_channels):\n",
        "      super(FPN5,self).__init__()\n",
        "      leaky = 0\n",
        "      if (out_channels <= 64):\n",
        "          leaky = 0.1\n",
        "      self.output1 = conv_bn1X1(in_channels_list[0], out_channels, stride = 1)\n",
        "      self.output2 = conv_bn1X1(in_channels_list[1], out_channels, stride = 1)\n",
        "      self.output3 = conv_bn1X1(in_channels_list[2], out_channels, stride = 1)\n",
        "      self.output4 = conv_bn1X1(in_channels_list[3], out_channels, stride = 1)\n",
        "      self.output5 = conv_bn1X1(in_channels_list[4], out_channels, stride = 1)\n",
        "\n",
        "      self.merge1 = conv_bn(out_channels, out_channels)\n",
        "      self.merge2 = conv_bn(out_channels, out_channels)\n",
        "      self.merge3 = conv_bn(out_channels, out_channels)\n",
        "      self.merge4 = conv_bn(out_channels, out_channels)\n",
        "\n",
        "  def forward(self, input):\n",
        "      # names = list(input.keys())\n",
        "\n",
        "      output1 = self.output1(input[0])\n",
        "      output2 = self.output2(input[1])\n",
        "      output3 = self.output3(input[2])\n",
        "      output4 = self.output4(input[3])\n",
        "      output5 = self.output5(input[4])\n",
        "\n",
        "      \n",
        "      up5 = F.interpolate(output5, size=[output4.size(2), output4.size(3)], mode=\"nearest\")\n",
        "      output4 = output4 + up5\n",
        "      output4 = self.merge4(output4)\n",
        "\n",
        "      up4 = F.interpolate(output4, size=[output3.size(2), output3.size(3)], mode=\"nearest\")\n",
        "      output3 = output3 + up4\n",
        "      output3 = self.merge3(output3)\n",
        "\n",
        "      up3 = F.interpolate(output3, size=[output2.size(2), output2.size(3)], mode=\"nearest\")\n",
        "      output2 = output2 + up3\n",
        "      output2 = self.merge2(output2)\n",
        "\n",
        "      up2 = F.interpolate(output2, size=[output1.size(2), output1.size(3)], mode=\"nearest\")\n",
        "      output1 = output1 + up2\n",
        "      output1 = self.merge1(output1)\n",
        "\n",
        "      out = [output1, output2, output3, output4, output5]\n",
        "      return out\n",
        "\n",
        "class FPN5_dw(nn.Module):\n",
        "  def __init__(self,in_channels_list,out_channels):\n",
        "      super(FPN5_dw,self).__init__()\n",
        "      leaky = 0\n",
        "      if (out_channels <= 64):\n",
        "          leaky = 0.1\n",
        "      self.output1 = conv_bn1X1(in_channels_list[0], out_channels, stride = 1)\n",
        "      self.output2 = conv_bn1X1(in_channels_list[1], out_channels, stride = 1)\n",
        "      self.output3 = conv_bn1X1(in_channels_list[2], out_channels, stride = 1)\n",
        "      self.output4 = conv_bn1X1(in_channels_list[3], out_channels, stride = 1)\n",
        "      self.output5 = conv_bn1X1(in_channels_list[4], out_channels, stride = 1)\n",
        "\n",
        "      self.merge1 = conv_dw(out_channels, out_channels, 1)\n",
        "      self.merge2 = conv_dw(out_channels, out_channels, 1)\n",
        "      self.merge3 = conv_dw(out_channels, out_channels, 1)\n",
        "      self.merge4 = conv_dw(out_channels, out_channels, 1)\n",
        "\n",
        "  def forward(self, input):\n",
        "      # names = list(input.keys())\n",
        "\n",
        "      output1 = self.output1(input[0])\n",
        "      output2 = self.output2(input[1])\n",
        "      output3 = self.output3(input[2])\n",
        "      output4 = self.output4(input[3])\n",
        "      output5 = self.output5(input[4])\n",
        "\n",
        "      \n",
        "      up5 = F.interpolate(output5, size=[output4.size(2), output4.size(3)], mode=\"nearest\")\n",
        "      output4 = output4 + up5\n",
        "      output4 = self.merge4(output4)\n",
        "\n",
        "      up4 = F.interpolate(output4, size=[output3.size(2), output3.size(3)], mode=\"nearest\")\n",
        "      output3 = output3 + up4\n",
        "      output3 = self.merge3(output3)\n",
        "\n",
        "      up3 = F.interpolate(output3, size=[output2.size(2), output2.size(3)], mode=\"nearest\")\n",
        "      output2 = output2 + up3\n",
        "      output2 = self.merge2(output2)\n",
        "\n",
        "      up2 = F.interpolate(output2, size=[output1.size(2), output1.size(3)], mode=\"nearest\")\n",
        "      output1 = output1 + up2\n",
        "      output1 = self.merge1(output1)\n",
        "\n",
        "      out = [output1, output2, output3, output4, output5]\n",
        "      return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm8MFhDbfMy9",
        "colab_type": "text"
      },
      "source": [
        "### A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ueff7kZyobVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Slim_c64(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_c64, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv2 = conv_dw(16, 32, 1)\n",
        "    self.conv3 = conv_dw(32, 32, 2)\n",
        "    self.conv4 = conv_dw(32, 32, 1)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 64, 2)\n",
        "    self.conv10 = conv_dw(64, 64, 1)\n",
        "    self.conv11 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv12 = conv_dw(64, 64, 2)\n",
        "    self.conv13 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv14 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      depth_conv2d(64, 64, kernel=3, stride=2, pad=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes);\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(64, 3 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 3 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 3 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [nn.Conv2d(64, 3 * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(64, 3 * num_classes, kernel_size=3, padding=1)]\n",
        "    landm_layers += [nn.Conv2d(64, 3 * 10, kernel_size=3, padding=1)]\n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.conv3(x2)\n",
        "    x4 = self.conv4(x3)\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14= self.conv14(x13)\n",
        "    detections.append(x14)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output\n",
        "\n",
        "class Slim_c64_a5_buggy(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_c64_a5, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv2 = conv_dw(16, 32, 1)\n",
        "    self.conv3 = conv_dw(32, 32, 2)\n",
        "    self.conv4 = conv_dw(32, 32, 1)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 64, 2)\n",
        "    self.conv10 = conv_dw(64, 64, 1)\n",
        "    self.conv11 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv12 = conv_dw(64, 64, 2)\n",
        "    self.conv13 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv14 = conv_dw(64, 64, 2)\n",
        "    self.conv15 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv16 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      depth_conv2d(64, 64, kernel=3, stride=2, pad=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes);\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [nn.Conv2d(64, 1 * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(64, 1 * num_classes, kernel_size=3, padding=1)]\n",
        "    landm_layers += [nn.Conv2d(64, 1 * 10, kernel_size=3, padding=1)]\n",
        "\n",
        "    loc_layers += [nn.Conv2d(64, 1 * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(64, 1 * num_classes, kernel_size=3, padding=1)]\n",
        "    landm_layers += [nn.Conv2d(64, 1 * 10, kernel_size=3, padding=1)]\n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.conv3(x2)\n",
        "    x4 = self.conv4(x3)\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14 = self.conv12(x13)\n",
        "    x15 = self.conv13(x14)\n",
        "    detections.append(x15)\n",
        "\n",
        "    x16 = self.conv14(x15)\n",
        "    detections.append(x16)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output\n",
        "\n",
        "class Slim_c64_a5(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_c64_a5, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv2 = conv_dw(16, 32, 1)\n",
        "    self.conv3 = conv_dw(32, 32, 2)\n",
        "    self.conv4 = conv_dw(32, 32, 1)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 64, 2)\n",
        "    self.conv10 = conv_dw(64, 64, 1)\n",
        "    self.conv11 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv12 = conv_dw(64, 64, 2)\n",
        "    self.conv13 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv14 = conv_dw(64, 64, 2)\n",
        "    self.conv15 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv16 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      depth_conv2d(64, 64, kernel=3, stride=2, pad=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes);\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [nn.Conv2d(64, 1 * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(64, 1 * num_classes, kernel_size=3, padding=1)]\n",
        "    landm_layers += [nn.Conv2d(64, 1 * 10, kernel_size=3, padding=1)]\n",
        "\n",
        "    loc_layers += [nn.Conv2d(64, 1 * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(64, 1 * num_classes, kernel_size=3, padding=1)]\n",
        "    landm_layers += [nn.Conv2d(64, 1 * 10, kernel_size=3, padding=1)]\n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.conv3(x2)\n",
        "    x4 = self.conv4(x3)\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14 = self.conv14(x13)\n",
        "    x15 = self.conv15(x14)\n",
        "    detections.append(x15)\n",
        "\n",
        "    x16 = self.conv16(x15)\n",
        "    detections.append(x16)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output\n",
        "\n",
        "class Slim_a5(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_a5, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv2 = conv_dw(16, 32, 1)\n",
        "    self.conv3 = conv_dw(32, 32, 2)\n",
        "    self.conv4 = conv_dw(32, 32, 1)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 128, 2)\n",
        "    self.conv10 = conv_dw(128, 128, 1)\n",
        "    self.conv11 = conv_dw(128, 128, 1)\n",
        "\n",
        "    self.conv12 = conv_dw(128, 256, 2)\n",
        "    self.conv13 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv14 = conv_dw(256, 256, 2)\n",
        "    self.conv15 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv16 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      depth_conv2d(64, 256, kernel=3, stride=2, pad=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes);\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(128, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(128, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(128, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(256, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [nn.Conv2d(256, 1 * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(256, 1 * num_classes, kernel_size=3, padding=1)]\n",
        "    landm_layers += [nn.Conv2d(256, 1 * 10, kernel_size=3, padding=1)]\n",
        "\n",
        "    loc_layers += [nn.Conv2d(256, 1 * 4, kernel_size=3, padding=1)]\n",
        "    conf_layers += [nn.Conv2d(256, 1 * num_classes, kernel_size=3, padding=1)]\n",
        "    landm_layers += [nn.Conv2d(256, 1 * 10, kernel_size=3, padding=1)]\n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.conv3(x2)\n",
        "    x4 = self.conv4(x3)\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14 = self.conv14(x13)\n",
        "    x15 = self.conv15(x14)\n",
        "    detections.append(x15)\n",
        "\n",
        "    x16 = self.conv14(x15)\n",
        "    detections.append(x16)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output\n",
        "\n",
        "\n",
        "    \n",
        "class Slim_a5_FPN(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_a5_FPN, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv2 = conv_dw(16, 32, 1)\n",
        "    self.conv3 = conv_dw(32, 32, 2)\n",
        "    self.conv4 = conv_dw(32, 32, 1)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 128, 2)\n",
        "    self.conv10 = conv_dw(128, 128, 1)\n",
        "    self.conv11 = conv_dw(128, 128, 1)\n",
        "\n",
        "    self.conv12 = conv_dw(128, 256, 2)\n",
        "    self.conv13 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv14 = conv_dw(256, 256, 2)\n",
        "    self.conv15 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv16 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      depth_conv2d(64, 256, kernel=3, stride=2, pad=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.fpn = FPN5([64, 128, 256, 256, 256], 64)\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes)\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "    \n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.conv3(x2)\n",
        "    x4 = self.conv4(x3)\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14 = self.conv14(x13)\n",
        "    x15 = self.conv15(x14)\n",
        "    detections.append(x15)\n",
        "\n",
        "    x16 = self.conv14(x15)\n",
        "    detections.append(x16)\n",
        "\n",
        "    detections = self.fpn(detections)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output\n",
        "\n",
        "\n",
        "class Slim_a5_FPN2(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_a5_FPN2, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv3 = conv_dw(16, 32, 2)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 128, 2)\n",
        "    self.conv10 = conv_dw(128, 128, 1)\n",
        "    self.conv11 = conv_dw(128, 128, 1)\n",
        "\n",
        "    self.conv12 = conv_dw(128, 256, 2)\n",
        "    self.conv13 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv14 = conv_dw(256, 256, 2)\n",
        "    self.conv15 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv16 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      depth_conv2d(64, 256, kernel=3, stride=2, pad=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.fpn = FPN5([64, 128, 256, 256, 256], 64)\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes)\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 1 * 10, kernel=3, pad=1)]\n",
        "    \n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x3 = self.conv3(x1)\n",
        "    x5 = self.conv5(x3)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14 = self.conv14(x13)\n",
        "    x15 = self.conv15(x14)\n",
        "    detections.append(x15)\n",
        "\n",
        "    x16 = self.conv14(x15)\n",
        "    detections.append(x16)\n",
        "\n",
        "    detections = self.fpn(detections)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output\n",
        "\n",
        "class Slim_c64_FPN(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_c64_FPN, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv2 = conv_dw(16, 32, 1)\n",
        "    self.conv3 = conv_dw(32, 32, 2)\n",
        "    self.conv4 = conv_dw(32, 32, 1)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 64, 2)\n",
        "    self.conv10 = conv_dw(64, 64, 1)\n",
        "    self.conv11 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv12 = conv_dw(64, 64, 2)\n",
        "    self.conv13 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv14 = conv_dw(64, 64, 2)\n",
        "    self.conv15 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv16 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      depth_conv2d(64, 64, kernel=3, stride=2, pad=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.fpn = FPN5([64, 64, 64, 64, 64], 64)\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes)\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(64, 3 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 3 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 3 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "    \n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.conv3(x2)\n",
        "    x4 = self.conv4(x3)\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14 = self.conv14(x13)\n",
        "    x15 = self.conv15(x14)\n",
        "    detections.append(x15)\n",
        "\n",
        "    x16 = self.conv14(x15)\n",
        "    detections.append(x16)\n",
        "\n",
        "    detections = self.fpn(detections)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output\n",
        "\n",
        "    \n",
        "class Slim_FPN(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_FPN, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv2 = conv_dw(16, 32, 1)\n",
        "    self.conv3 = conv_dw(32, 32, 2)\n",
        "    self.conv4 = conv_dw(32, 32, 1)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 128, 2)\n",
        "    self.conv10 = conv_dw(128, 128, 1)\n",
        "    self.conv11 = conv_dw(128, 128, 1)\n",
        "\n",
        "    self.conv12 = conv_dw(128, 256, 2)\n",
        "    self.conv13 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv14 = conv_dw(256, 256, 2)\n",
        "    self.conv15 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv16 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      depth_conv2d(64, 256, kernel=3, stride=2, pad=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.fpn = FPN5([64, 128, 256, 256, 256], 64)\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes)\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(64, 3 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 3 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 3 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "    \n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.conv3(x2)\n",
        "    x4 = self.conv4(x3)\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14 = self.conv14(x13)\n",
        "    x15 = self.conv15(x14)\n",
        "    detections.append(x15)\n",
        "\n",
        "    x16 = self.conv14(x15)\n",
        "    detections.append(x16)\n",
        "\n",
        "    detections = self.fpn(detections)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output\n",
        "\n",
        "class Slim_FPN_dw256(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_FPN_dw256, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv2 = conv_dw(16, 32, 1)\n",
        "    self.conv3 = conv_dw(32, 32, 2)\n",
        "    self.conv4 = conv_dw(32, 32, 1)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 128, 2)\n",
        "    self.conv10 = conv_dw(128, 128, 1)\n",
        "    self.conv11 = conv_dw(128, 128, 1)\n",
        "\n",
        "    self.conv12 = conv_dw(128, 256, 2)\n",
        "    self.conv13 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv14 = conv_dw(256, 256, 2)\n",
        "    self.conv15 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv16 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      depth_conv2d(64, 256, kernel=3, stride=2, pad=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.fpn = FPN_dw([64, 128, 256, 256, 256], 256)\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes)\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(256, 3 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 3 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 3 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(256, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(256, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(256, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(256, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 2 * 10, kernel=3, pad=1)]\n",
        "    \n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.conv3(x2)\n",
        "    x4 = self.conv4(x3)\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14 = self.conv14(x13)\n",
        "    x15 = self.conv15(x14)\n",
        "    detections.append(x15)\n",
        "\n",
        "    x16 = self.conv14(x15)\n",
        "    detections.append(x16)\n",
        "\n",
        "    detections = self.fpn(detections)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output\n",
        "\n",
        "class Slim_a5_FPN_dw256(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_a5_FPN_dw256, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv2 = conv_dw(16, 32, 1)\n",
        "    self.conv3 = conv_dw(32, 32, 2)\n",
        "    self.conv4 = conv_dw(32, 32, 1)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 128, 2)\n",
        "    self.conv10 = conv_dw(128, 128, 1)\n",
        "    self.conv11 = conv_dw(128, 128, 1)\n",
        "\n",
        "    self.conv12 = conv_dw(128, 256, 2)\n",
        "    self.conv13 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv14 = conv_dw(256, 256, 2)\n",
        "    self.conv15 = conv_dw(256, 256, 1)\n",
        "\n",
        "    self.conv16 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      depth_conv2d(64, 256, kernel=3, stride=2, pad=1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.fpn = FPN5_dw([64, 128, 256, 256, 256], 256)\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes)\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(256, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(256, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(256, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(256, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 1 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(256, 1 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(256, 1 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(256, 1 * 10, kernel=3, pad=1)]\n",
        "    \n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.conv3(x2)\n",
        "    x4 = self.conv4(x3)\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14 = self.conv14(x13)\n",
        "    x15 = self.conv15(x14)\n",
        "    detections.append(x15)\n",
        "\n",
        "    x16 = self.conv14(x15)\n",
        "    detections.append(x16)\n",
        "\n",
        "    detections = self.fpn(detections)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output\n",
        "\n",
        "class Slim_64_FPNx_dw64(nn.Module):\n",
        "  def __init__(self, cfg = None, phase = 'train'):\n",
        "    \"\"\"\n",
        "    :param cfg:  Network related settings.\n",
        "    :param phase: train or test.\n",
        "    \"\"\"\n",
        "    super(Slim_64_FPNx_dw64, self).__init__()\n",
        "    self.phase = phase\n",
        "    self.num_classes = 2\n",
        "\n",
        "    self.conv1 = conv_bn(3, 16, 2)\n",
        "    self.conv2 = conv_dw(16, 32, 1)\n",
        "    self.conv3 = conv_dw(32, 32, 2)\n",
        "    self.conv4 = conv_dw(32, 32, 1)\n",
        "    self.conv5 = conv_dw(32, 64, 2)\n",
        "    self.conv6 = conv_dw(64, 64, 1)\n",
        "    self.conv7 = conv_dw(64, 64, 1)\n",
        "    self.conv8 = conv_dw(64, 64, 1)\n",
        "\n",
        "    self.conv9 = conv_dw(64, 64, 2)\n",
        "    self.conv10 = conv_dw(64, 64, 1)\n",
        "    self.conv11 = nn.Sequential(\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1)\n",
        "    )\n",
        "\n",
        "    self.conv12 = conv_dw(64, 64, 2)\n",
        "    self.conv13 = nn.Sequential(\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1)\n",
        "    )\n",
        "\n",
        "    self.conv14 = conv_dw(64, 64, 2)\n",
        "    self.conv15 = nn.Sequential(\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1)\n",
        "    )\n",
        "\n",
        "    self.conv16 = nn.Sequential(\n",
        "        conv_dw(64, 64, 2),\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1),\n",
        "        conv_dw(64, 64, 1)\n",
        "    )\n",
        "    self.fpn = FPN5_dw([64, 64, 64, 64, 64], 64)\n",
        "    self.loc, self.conf, self.landm = self.multibox(self.num_classes)\n",
        "\n",
        "  def multibox(self, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    landm_layers = []\n",
        "    loc_layers += [depth_conv2d(64, 3 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 3 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 3 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "\n",
        "    loc_layers += [depth_conv2d(64, 2 * 4, kernel=3, pad=1)]\n",
        "    conf_layers += [depth_conv2d(64, 2 * num_classes, kernel=3, pad=1)]\n",
        "    landm_layers += [depth_conv2d(64, 2 * 10, kernel=3, pad=1)]\n",
        "    \n",
        "    return nn.Sequential(*loc_layers), nn.Sequential(*conf_layers), nn.Sequential(*landm_layers)\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    detections = list()\n",
        "    loc = list()\n",
        "    conf = list()\n",
        "    landm = list()\n",
        "\n",
        "    x1 = self.conv1(inputs)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.conv3(x2)\n",
        "    x4 = self.conv4(x3)\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.conv6(x5)\n",
        "    x7 = self.conv7(x6)\n",
        "    x8 = self.conv8(x7)\n",
        "    detections.append(x8)\n",
        "\n",
        "    x9 = self.conv9(x8)\n",
        "    x10 = self.conv10(x9)\n",
        "    x11 = self.conv11(x10)\n",
        "    detections.append(x11)\n",
        "\n",
        "    x12 = self.conv12(x11)\n",
        "    x13 = self.conv13(x12)\n",
        "    detections.append(x13)\n",
        "\n",
        "    x14 = self.conv14(x13)\n",
        "    x15 = self.conv15(x14)\n",
        "    detections.append(x15)\n",
        "\n",
        "    x16 = self.conv14(x15)\n",
        "    detections.append(x16)\n",
        "\n",
        "    detections = self.fpn(detections)\n",
        "\n",
        "    for (x, l, c, lam) in zip(detections, self.loc, self.conf, self.landm):\n",
        "      loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "      conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "      landm.append(lam(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "    bbox_regressions = torch.cat([o.view(o.size(0), -1, 4) for o in loc], 1)\n",
        "    classifications = torch.cat([o.view(o.size(0), -1, 2) for o in conf], 1)\n",
        "    ldm_regressions = torch.cat([o.view(o.size(0), -1, 10) for o in landm], 1)\n",
        "\n",
        "    if self.phase == 'train':\n",
        "      output = (bbox_regressions, classifications, ldm_regressions)\n",
        "    else:\n",
        "      output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fyuvby69fSB9"
      },
      "source": [
        "### B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IcWjmuSPfSCS",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models.detection.backbone_utils as backbone_utils\n",
        "import torchvision.models._utils as _utils\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "from models.net import MobileNetV1 as MobileNetV1\n",
        "from models.net import FPN as FPN\n",
        "from models.net import SSH as SSH\n",
        "\n",
        "\n",
        "\n",
        "class ClassHead(nn.Module):\n",
        "    def __init__(self,inchannels=512,num_anchors=3):\n",
        "        super(ClassHead,self).__init__()\n",
        "        self.num_anchors = num_anchors\n",
        "        self.conv1x1 = nn.Conv2d(inchannels,self.num_anchors*2,kernel_size=(1,1),stride=1,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.conv1x1(x)\n",
        "        out = out.permute(0,2,3,1).contiguous()\n",
        "        \n",
        "        return out.view(out.shape[0], -1, 2)\n",
        "\n",
        "class BboxHead(nn.Module):\n",
        "    def __init__(self,inchannels=512,num_anchors=3):\n",
        "        super(BboxHead,self).__init__()\n",
        "        self.conv1x1 = nn.Conv2d(inchannels,num_anchors*4,kernel_size=(1,1),stride=1,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.conv1x1(x)\n",
        "        out = out.permute(0,2,3,1).contiguous()\n",
        "\n",
        "        return out.view(out.shape[0], -1, 4)\n",
        "\n",
        "class LandmarkHead(nn.Module):\n",
        "    def __init__(self,inchannels=512,num_anchors=3):\n",
        "        super(LandmarkHead,self).__init__()\n",
        "        self.conv1x1 = nn.Conv2d(inchannels,num_anchors*10,kernel_size=(1,1),stride=1,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.conv1x1(x)\n",
        "        out = out.permute(0,2,3,1).contiguous()\n",
        "\n",
        "        return out.view(out.shape[0], -1, 10)\n",
        "\n",
        "class MnetFixedA0(nn.Module):\n",
        "    def __init__(self, cfg = None, phase = 'train'):\n",
        "        \"\"\"\n",
        "        :param cfg:  Network related settings.\n",
        "        :param phase: train or test.\n",
        "        \"\"\"\n",
        "        super(MnetFixedA0,self).__init__()\n",
        "        self.phase = phase\n",
        "        backbone = None\n",
        "        if cfg['name'] == 'mobilenet0.25':\n",
        "            backbone = MobileNetV1()\n",
        "            if cfg['pretrain']:\n",
        "                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\n",
        "                from collections import OrderedDict\n",
        "                new_state_dict = OrderedDict()\n",
        "                for k, v in checkpoint['state_dict'].items():\n",
        "                    name = k[7:]  # remove module.\n",
        "                    new_state_dict[name] = v\n",
        "                # load params\n",
        "                backbone.load_state_dict(new_state_dict)\n",
        "        elif cfg['name'] == 'Resnet50':\n",
        "            import torchvision.models as models\n",
        "            backbone = models.resnet50(pretrained=cfg['pretrain'])\n",
        "\n",
        "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
        "        in_channels_stage2 = cfg['in_channel']\n",
        "        in_channels_list = [\n",
        "            in_channels_stage2 * 2,\n",
        "            in_channels_stage2 * 4,\n",
        "            in_channels_stage2 * 8,\n",
        "        ]\n",
        "        out_channels = cfg['out_channel']\n",
        "        self.fpn = FPN(in_channels_list,out_channels)\n",
        "        self.ssh1 = SSH(out_channels, out_channels)\n",
        "        self.ssh2 = SSH(out_channels, out_channels)\n",
        "        self.ssh3 = SSH(out_channels, out_channels)\n",
        "\n",
        "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "\n",
        "    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        classhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            classhead.append(ClassHead(inchannels,1 if i == 0 else anchor_num))\n",
        "        return classhead\n",
        "    \n",
        "    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        bboxhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            bboxhead.append(BboxHead(inchannels,1 if i == 0 else anchor_num))\n",
        "        return bboxhead\n",
        "\n",
        "    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        landmarkhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            landmarkhead.append(LandmarkHead(inchannels,1 if i == 0 else anchor_num))\n",
        "        return landmarkhead\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        out = self.body(inputs)\n",
        "\n",
        "        # FPN\n",
        "        fpn = self.fpn(out)\n",
        "\n",
        "        # SSH\n",
        "        feature1 = self.ssh1(fpn[0])\n",
        "        feature2 = self.ssh2(fpn[1])\n",
        "        feature3 = self.ssh3(fpn[2])\n",
        "        features = [feature1, feature2, feature3]\n",
        "\n",
        "        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\n",
        "        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "\n",
        "        if self.phase == 'train':\n",
        "            output = (bbox_regressions, classifications, ldm_regressions)\n",
        "        else:\n",
        "            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "        return output\n",
        "\n",
        "        \n",
        "class MnetNoSsh(nn.Module):\n",
        "    def __init__(self, cfg = None, phase = 'train'):\n",
        "        \"\"\"\n",
        "        :param cfg:  Network related settings.\n",
        "        :param phase: train or test.\n",
        "        \"\"\"\n",
        "        super(MnetNoSsh,self).__init__()\n",
        "        self.phase = phase\n",
        "        backbone = None\n",
        "        if cfg['name'] == 'mobilenet0.25':\n",
        "            backbone = MobileNetV1()\n",
        "            if cfg['pretrain']:\n",
        "                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\n",
        "                from collections import OrderedDict\n",
        "                new_state_dict = OrderedDict()\n",
        "                for k, v in checkpoint['state_dict'].items():\n",
        "                    name = k[7:]  # remove module.\n",
        "                    new_state_dict[name] = v\n",
        "                # load params\n",
        "                backbone.load_state_dict(new_state_dict)\n",
        "        elif cfg['name'] == 'Resnet50':\n",
        "            import torchvision.models as models\n",
        "            backbone = models.resnet50(pretrained=cfg['pretrain'])\n",
        "\n",
        "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
        "        in_channels_stage2 = cfg['in_channel']\n",
        "        in_channels_list = [\n",
        "            in_channels_stage2 * 2,\n",
        "            in_channels_stage2 * 4,\n",
        "            in_channels_stage2 * 8,\n",
        "        ]\n",
        "        out_channels = cfg['out_channel']\n",
        "        self.fpn = FPN(in_channels_list,out_channels)\n",
        "\n",
        "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "\n",
        "    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        classhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            classhead.append(ClassHead(inchannels,anchor_num))\n",
        "        return classhead\n",
        "    \n",
        "    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        bboxhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            bboxhead.append(BboxHead(inchannels,anchor_num))\n",
        "        return bboxhead\n",
        "\n",
        "    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        landmarkhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            landmarkhead.append(LandmarkHead(inchannels,anchor_num))\n",
        "        return landmarkhead\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        out = self.body(inputs)\n",
        "\n",
        "        # FPN\n",
        "        fpn = self.fpn(out)\n",
        "\n",
        "        features = fpn\n",
        "\n",
        "        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\n",
        "        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "\n",
        "        if self.phase == 'train':\n",
        "            output = (bbox_regressions, classifications, ldm_regressions)\n",
        "        else:\n",
        "            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "        return output\n",
        "\n",
        "class MnetSSDFixedA0(nn.Module):\n",
        "    def __init__(self, cfg = None, phase = 'train'):\n",
        "        \"\"\"\n",
        "        :param cfg:  Network related settings.\n",
        "        :param phase: train or test.\n",
        "        \"\"\"\n",
        "        super(MnetSSDFixedA0,self).__init__()\n",
        "        self.phase = phase\n",
        "        backbone = None\n",
        "        if cfg['name'] == 'mobilenet0.25':\n",
        "            backbone = MobileNetV1()\n",
        "            if cfg['pretrain']:\n",
        "                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\n",
        "                from collections import OrderedDict\n",
        "                new_state_dict = OrderedDict()\n",
        "                for k, v in checkpoint['state_dict'].items():\n",
        "                    name = k[7:]  # remove module.\n",
        "                    new_state_dict[name] = v\n",
        "                # load params\n",
        "                backbone.load_state_dict(new_state_dict)\n",
        "        elif cfg['name'] == 'Resnet50':\n",
        "            import torchvision.models as models\n",
        "            backbone = models.resnet50(pretrained=cfg['pretrain'])\n",
        "\n",
        "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
        "        in_channels_stage2 = cfg['in_channel']\n",
        "        in_channels_list = [\n",
        "            in_channels_stage2 * 2,\n",
        "            in_channels_stage2 * 4,\n",
        "            in_channels_stage2 * 8,\n",
        "        ]\n",
        "        out_channels = cfg['out_channel']\n",
        "\n",
        "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=in_channels_list)\n",
        "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=in_channels_list)\n",
        "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=in_channels_list)\n",
        "\n",
        "    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        classhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            classhead.append(ClassHead(inchannels[i],1 if i == 0 else anchor_num))\n",
        "        return classhead\n",
        "    \n",
        "    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        bboxhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            bboxhead.append(BboxHead(inchannels[i],1 if i == 0 else anchor_num))\n",
        "        return bboxhead\n",
        "\n",
        "    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        landmarkhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            landmarkhead.append(LandmarkHead(inchannels[i],1 if i == 0 else anchor_num))\n",
        "        return landmarkhead\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        out = self.body(inputs)\n",
        "\n",
        "        features = list(out.values())\n",
        "\n",
        "        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\n",
        "        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "\n",
        "        if self.phase == 'train':\n",
        "            output = (bbox_regressions, classifications, ldm_regressions)\n",
        "        else:\n",
        "            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "        return output\n",
        "\n",
        "      \n",
        "class MnetSSD(nn.Module):\n",
        "    def __init__(self, cfg = None, phase = 'train'):\n",
        "        \"\"\"\n",
        "        :param cfg:  Network related settings.\n",
        "        :param phase: train or test.\n",
        "        \"\"\"\n",
        "        super(MnetSSD,self).__init__()\n",
        "        self.phase = phase\n",
        "        backbone = None\n",
        "        if cfg['name'] == 'mobilenet0.25':\n",
        "            backbone = MobileNetV1()\n",
        "            if cfg['pretrain']:\n",
        "                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\n",
        "                from collections import OrderedDict\n",
        "                new_state_dict = OrderedDict()\n",
        "                for k, v in checkpoint['state_dict'].items():\n",
        "                    name = k[7:]  # remove module.\n",
        "                    new_state_dict[name] = v\n",
        "                # load params\n",
        "                backbone.load_state_dict(new_state_dict)\n",
        "        elif cfg['name'] == 'Resnet50':\n",
        "            import torchvision.models as models\n",
        "            backbone = models.resnet50(pretrained=cfg['pretrain'])\n",
        "\n",
        "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
        "        in_channels_stage2 = cfg['in_channel']\n",
        "        in_channels_list = [\n",
        "            in_channels_stage2 * 2,\n",
        "            in_channels_stage2 * 4,\n",
        "            in_channels_stage2 * 8,\n",
        "        ]\n",
        "        out_channels = cfg['out_channel']\n",
        "\n",
        "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=in_channels_list)\n",
        "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=in_channels_list)\n",
        "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=in_channels_list)\n",
        "\n",
        "    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        classhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            classhead.append(ClassHead(inchannels[i],anchor_num))\n",
        "        return classhead\n",
        "    \n",
        "    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        bboxhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            bboxhead.append(BboxHead(inchannels[i],anchor_num))\n",
        "        return bboxhead\n",
        "\n",
        "    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        landmarkhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            landmarkhead.append(LandmarkHead(inchannels[i],anchor_num))\n",
        "        return landmarkhead\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        out = self.body(inputs)\n",
        "\n",
        "        features = list(out.values())\n",
        "\n",
        "        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\n",
        "        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "\n",
        "        if self.phase == 'train':\n",
        "            output = (bbox_regressions, classifications, ldm_regressions)\n",
        "        else:\n",
        "            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "        return output\n",
        "\n",
        "class MnetNorm(RetinaFace):\n",
        "  def forward(self, inputs):\n",
        "    normalized_inputs = inputs / 255.0\n",
        "    return super().forward(normalized_inputs)\n",
        "\n",
        "\n",
        "\n",
        "class MobileNetV1x(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV1x, self).__init__()\n",
        "        self.stage1 = nn.Sequential(\n",
        "            conv_bn(3, 8, 2),    # 3\n",
        "            conv_dw(8, 16, 1),   # 7\n",
        "            conv_dw(16, 32, 2),  # 11\n",
        "            conv_dw(32, 32, 1),  # 19\n",
        "            conv_dw(32, 64, 2),  # 27\n",
        "            conv_dw(64, 64, 1),  # 43\n",
        "            conv_dw(64, 64, 1),  # 43\n",
        "            conv_dw(64, 64, 1),  # 43\n",
        "            conv_dw(64, 64, 1),  # 43\n",
        "        )\n",
        "        self.stage2 = nn.Sequential(\n",
        "            conv_dw(64, 128, 2),  # 43 + 16 = 59\n",
        "            conv_dw(128, 128, 1), # 59 + 32 = 91\n",
        "            conv_dw(128, 128, 1), # 91 + 32 = 123\n",
        "            conv_dw(128, 128, 1), # 123 + 32 = 155\n",
        "            conv_dw(128, 128, 1), # 155 + 32 = 187\n",
        "            conv_dw(128, 128, 1), # 187 + 32 = 219\n",
        "            conv_dw(128, 128, 1), # 187 + 32 = 219\n",
        "            conv_dw(128, 128, 1), # 187 + 32 = 219\n",
        "        )\n",
        "        self.stage3 = nn.Sequential(\n",
        "            conv_dw(128, 256, 2), # 219 +3 2 = 241\n",
        "            conv_dw(256, 256, 1), # 241 + 64 = 301\n",
        "            conv_dw(256, 256, 1), # 241 + 64 = 301\n",
        "        )\n",
        "        self.avg = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(256, 1000)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.avg(x)\n",
        "        # x = self.model(x)\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class MnetX(nn.Module):\n",
        "    def __init__(self, cfg = None, phase = 'train'):\n",
        "        \"\"\"\n",
        "        :param cfg:  Network related settings.\n",
        "        :param phase: train or test.\n",
        "        \"\"\"\n",
        "        super(MnetX,self).__init__()\n",
        "        self.phase = phase\n",
        "        backbone = None\n",
        "        if cfg['name'] == 'mobilenet0.25':\n",
        "            backbone = MobileNetV1x()\n",
        "            if cfg['pretrain']:\n",
        "                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\n",
        "                from collections import OrderedDict\n",
        "                new_state_dict = OrderedDict()\n",
        "                for k, v in checkpoint['state_dict'].items():\n",
        "                    name = k[7:]  # remove module.\n",
        "                    new_state_dict[name] = v\n",
        "                # load params\n",
        "                backbone.load_state_dict(new_state_dict)\n",
        "        elif cfg['name'] == 'Resnet50':\n",
        "            import torchvision.models as models\n",
        "            backbone = models.resnet50(pretrained=cfg['pretrain'])\n",
        "\n",
        "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
        "        in_channels_stage2 = cfg['in_channel']\n",
        "        in_channels_list = [\n",
        "            in_channels_stage2 * 2,\n",
        "            in_channels_stage2 * 4,\n",
        "            in_channels_stage2 * 8,\n",
        "        ]\n",
        "        out_channels = cfg['out_channel']\n",
        "        self.fpn = FPN(in_channels_list,out_channels)\n",
        "        self.ssh1 = SSH(out_channels, out_channels)\n",
        "        self.ssh2 = SSH(out_channels, out_channels)\n",
        "        self.ssh3 = SSH(out_channels, out_channels)\n",
        "\n",
        "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "\n",
        "    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        classhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            classhead.append(ClassHead(inchannels,anchor_num))\n",
        "        return classhead\n",
        "    \n",
        "    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        bboxhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            bboxhead.append(BboxHead(inchannels,anchor_num))\n",
        "        return bboxhead\n",
        "\n",
        "    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        landmarkhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            landmarkhead.append(LandmarkHead(inchannels,anchor_num))\n",
        "        return landmarkhead\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        out = self.body(inputs)\n",
        "\n",
        "        # FPN\n",
        "        fpn = self.fpn(out)\n",
        "\n",
        "        # SSH\n",
        "        feature1 = self.ssh1(fpn[0])\n",
        "        feature2 = self.ssh2(fpn[1])\n",
        "        feature3 = self.ssh3(fpn[2])\n",
        "        features = [feature1, feature2, feature3]\n",
        "\n",
        "        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\n",
        "        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "\n",
        "        if self.phase == 'train':\n",
        "            output = (bbox_regressions, classifications, ldm_regressions)\n",
        "        else:\n",
        "            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "        return output\n",
        "\n",
        "\n",
        "class MobileNetV1_128(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV1_128, self).__init__()\n",
        "        self.stage1 = nn.Sequential(\n",
        "            conv_bn(3, 16, 2),    # 3\n",
        "            conv_dw(16, 32, 1),   # 7\n",
        "            conv_dw(32, 64, 2),  # 11\n",
        "            conv_dw(64, 64, 1),  # 19\n",
        "            conv_dw(64, 64, 2),  # 27\n",
        "            conv_dw(64, 128, 1),  # 43\n",
        "        )\n",
        "        self.stage2 = nn.Sequential(\n",
        "            conv_dw(128, 128, 2),  # 43 + 16 = 59\n",
        "            conv_dw(128, 128, 1), # 59 + 32 = 91\n",
        "            conv_dw(128, 128, 1), # 91 + 32 = 123\n",
        "            conv_dw(128, 128, 1), # 123 + 32 = 155\n",
        "            conv_dw(128, 128, 1), # 155 + 32 = 187\n",
        "            conv_dw(128, 128, 1), # 187 + 32 = 219\n",
        "        )\n",
        "        self.stage3 = nn.Sequential(\n",
        "            conv_dw(128, 256, 2), # 219 +3 2 = 241\n",
        "            conv_dw(256, 256, 1), # 241 + 64 = 301\n",
        "        )\n",
        "        self.avg = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(256, 1000)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.avg(x)\n",
        "        # x = self.model(x)\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "class Mnet_128(nn.Module):\n",
        "    def __init__(self, cfg = None, phase = 'train'):\n",
        "        \"\"\"\n",
        "        :param cfg:  Network related settings.\n",
        "        :param phase: train or test.\n",
        "        \"\"\"\n",
        "        super(Mnet_128,self).__init__()\n",
        "        self.phase = phase\n",
        "        backbone = None\n",
        "        if cfg['name'] == 'mobilenet0.25':\n",
        "            backbone = MobileNetV1_128()\n",
        "            if cfg['pretrain']:\n",
        "                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\n",
        "                from collections import OrderedDict\n",
        "                new_state_dict = OrderedDict()\n",
        "                for k, v in checkpoint['state_dict'].items():\n",
        "                    name = k[7:]  # remove module.\n",
        "                    new_state_dict[name] = v\n",
        "                # load params\n",
        "                backbone.load_state_dict(new_state_dict)\n",
        "        elif cfg['name'] == 'Resnet50':\n",
        "            import torchvision.models as models\n",
        "            backbone = models.resnet50(pretrained=cfg['pretrain'])\n",
        "\n",
        "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
        "        in_channels_stage2 = cfg['in_channel']\n",
        "        in_channels_list = [\n",
        "            in_channels_stage2 * 2,\n",
        "            in_channels_stage2 * 2,\n",
        "            in_channels_stage2 * 4,\n",
        "        ]\n",
        "        out_channels = cfg['out_channel']\n",
        "        self.fpn = FPN(in_channels_list,out_channels)\n",
        "        self.ssh1 = SSH(out_channels, out_channels)\n",
        "        self.ssh2 = SSH(out_channels, out_channels)\n",
        "        self.ssh3 = SSH(out_channels, out_channels)\n",
        "\n",
        "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "\n",
        "    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        classhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            classhead.append(ClassHead(inchannels,anchor_num))\n",
        "        return classhead\n",
        "    \n",
        "    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        bboxhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            bboxhead.append(BboxHead(inchannels,anchor_num))\n",
        "        return bboxhead\n",
        "\n",
        "    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        landmarkhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            landmarkhead.append(LandmarkHead(inchannels,anchor_num))\n",
        "        return landmarkhead\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        out = self.body(inputs)\n",
        "\n",
        "        # FPN\n",
        "        fpn = self.fpn(out)\n",
        "\n",
        "        # SSH\n",
        "        feature1 = self.ssh1(fpn[0])\n",
        "        feature2 = self.ssh2(fpn[1])\n",
        "        feature3 = self.ssh3(fpn[2])\n",
        "        features = [feature1, feature2, feature3]\n",
        "\n",
        "        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\n",
        "        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "\n",
        "        if self.phase == 'train':\n",
        "            output = (bbox_regressions, classifications, ldm_regressions)\n",
        "        else:\n",
        "            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "        return output\n",
        "\n",
        "\n",
        "class MobileNetV1_s1L(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV1_s1L, self).__init__()\n",
        "        self.stage1 = nn.Sequential(\n",
        "            conv_bn(3, 16, 2),    # 3\n",
        "            conv_dw(16, 32, 1),   # 7\n",
        "            conv_dw(32, 64, 2),  # 11\n",
        "            conv_dw(64, 64, 1),  # 19\n",
        "            conv_dw(64, 64, 2),  # 27\n",
        "            conv_dw(64, 64, 1),  # 43\n",
        "        )\n",
        "        self.stage2 = nn.Sequential(\n",
        "            conv_dw(64, 128, 2),  # 43 + 16 = 59\n",
        "            conv_dw(128, 128, 1), # 59 + 32 = 91\n",
        "            conv_dw(128, 128, 1), # 91 + 32 = 123\n",
        "            conv_dw(128, 128, 1), # 123 + 32 = 155\n",
        "            conv_dw(128, 128, 1), # 155 + 32 = 187\n",
        "            conv_dw(128, 128, 1), # 187 + 32 = 219\n",
        "        )\n",
        "        self.stage3 = nn.Sequential(\n",
        "            conv_dw(128, 256, 2), # 219 +3 2 = 241\n",
        "            conv_dw(256, 256, 1), # 241 + 64 = 301\n",
        "        )\n",
        "        self.avg = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(256, 1000)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.avg(x)\n",
        "        # x = self.model(x)\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "        \n",
        "class Mnet_s1L(nn.Module):\n",
        "    def __init__(self, cfg = None, phase = 'train'):\n",
        "        \"\"\"\n",
        "        :param cfg:  Network related settings.\n",
        "        :param phase: train or test.\n",
        "        \"\"\"\n",
        "        super(Mnet_s1L,self).__init__()\n",
        "        self.phase = phase\n",
        "        backbone = None\n",
        "        if cfg['name'] == 'mobilenet0.25':\n",
        "            backbone = MobileNetV1_s1L()\n",
        "            if cfg['pretrain']:\n",
        "                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\n",
        "                from collections import OrderedDict\n",
        "                new_state_dict = OrderedDict()\n",
        "                for k, v in checkpoint['state_dict'].items():\n",
        "                    name = k[7:]  # remove module.\n",
        "                    new_state_dict[name] = v\n",
        "                # load params\n",
        "                backbone.load_state_dict(new_state_dict)\n",
        "        elif cfg['name'] == 'Resnet50':\n",
        "            import torchvision.models as models\n",
        "            backbone = models.resnet50(pretrained=cfg['pretrain'])\n",
        "\n",
        "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
        "        in_channels_stage2 = cfg['in_channel']\n",
        "        in_channels_list = [\n",
        "            in_channels_stage2 * 2,\n",
        "            in_channels_stage2 * 4,\n",
        "            in_channels_stage2 * 8,\n",
        "        ]\n",
        "        out_channels = cfg['out_channel']\n",
        "        self.fpn = FPN(in_channels_list,out_channels)\n",
        "        self.ssh1 = SSH(out_channels, out_channels)\n",
        "        self.ssh2 = SSH(out_channels, out_channels)\n",
        "        self.ssh3 = SSH(out_channels, out_channels)\n",
        "\n",
        "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "\n",
        "    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        classhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            classhead.append(ClassHead(inchannels,anchor_num))\n",
        "        return classhead\n",
        "    \n",
        "    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        bboxhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            bboxhead.append(BboxHead(inchannels,anchor_num))\n",
        "        return bboxhead\n",
        "\n",
        "    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        landmarkhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            landmarkhead.append(LandmarkHead(inchannels,anchor_num))\n",
        "        return landmarkhead\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        out = self.body(inputs)\n",
        "\n",
        "        # FPN\n",
        "        fpn = self.fpn(out)\n",
        "\n",
        "        # SSH\n",
        "        feature1 = self.ssh1(fpn[0])\n",
        "        feature2 = self.ssh2(fpn[1])\n",
        "        feature3 = self.ssh3(fpn[2])\n",
        "        features = [feature1, feature2, feature3]\n",
        "\n",
        "        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\n",
        "        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "\n",
        "        if self.phase == 'train':\n",
        "            output = (bbox_regressions, classifications, ldm_regressions)\n",
        "        else:\n",
        "            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "        return output\n",
        "\n",
        "class MobileNetV1_s0_160(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV1_s0_160, self).__init__()\n",
        "        self.stage1 = nn.Sequential(\n",
        "            conv_bn(3, 8, 2),    # 3\n",
        "            conv_dw(8, 16, 1),   # 7\n",
        "            conv_dw(16, 32, 2),  # 11\n",
        "            conv_dw(32, 32, 1),  # 19\n",
        "            conv_dw(32, 64, 1),  # 27\n",
        "            conv_dw(64, 64, 1),  # 43\n",
        "        )\n",
        "        self.stage2 = nn.Sequential(\n",
        "            conv_dw(64, 128, 2),  # 43 + 16 = 59\n",
        "            conv_dw(128, 128, 1), # 59 + 32 = 91\n",
        "            conv_dw(128, 128, 1), # 91 + 32 = 123\n",
        "            conv_dw(128, 128, 1), # 123 + 32 = 155\n",
        "            conv_dw(128, 128, 1), # 155 + 32 = 187\n",
        "            conv_dw(128, 128, 1), # 187 + 32 = 219\n",
        "        )\n",
        "        self.stage3 = nn.Sequential(\n",
        "            conv_dw(128, 256, 2), # 219 +3 2 = 241\n",
        "            conv_dw(256, 256, 1), # 241 + 64 = 301\n",
        "        )\n",
        "        self.avg = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(256, 1000)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.avg(x)\n",
        "        # x = self.model(x)\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "class Mnet_s0_160(nn.Module):\n",
        "    def __init__(self, cfg = None, phase = 'train'):\n",
        "        \"\"\"\n",
        "        :param cfg:  Network related settings.\n",
        "        :param phase: train or test.\n",
        "        \"\"\"\n",
        "        super(Mnet_s0_160,self).__init__()\n",
        "        self.phase = phase\n",
        "        backbone = None\n",
        "        if cfg['name'] == 'mobilenet0.25':\n",
        "            backbone = MobileNetV1_s0_160()\n",
        "            if cfg['pretrain']:\n",
        "                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\n",
        "                from collections import OrderedDict\n",
        "                new_state_dict = OrderedDict()\n",
        "                for k, v in checkpoint['state_dict'].items():\n",
        "                    name = k[7:]  # remove module.\n",
        "                    new_state_dict[name] = v\n",
        "                # load params\n",
        "                backbone.load_state_dict(new_state_dict)\n",
        "        elif cfg['name'] == 'Resnet50':\n",
        "            import torchvision.models as models\n",
        "            backbone = models.resnet50(pretrained=cfg['pretrain'])\n",
        "\n",
        "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
        "        in_channels_stage2 = cfg['in_channel']\n",
        "        in_channels_list = [\n",
        "            in_channels_stage2 * 2,\n",
        "            in_channels_stage2 * 4,\n",
        "            in_channels_stage2 * 8,\n",
        "        ]\n",
        "        out_channels = cfg['out_channel']\n",
        "        self.fpn = FPN(in_channels_list,out_channels)\n",
        "        self.ssh1 = SSH(out_channels, out_channels)\n",
        "        self.ssh2 = SSH(out_channels, out_channels)\n",
        "        self.ssh3 = SSH(out_channels, out_channels)\n",
        "\n",
        "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "\n",
        "    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        classhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            classhead.append(ClassHead(inchannels,anchor_num))\n",
        "        return classhead\n",
        "    \n",
        "    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        bboxhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            bboxhead.append(BboxHead(inchannels,anchor_num))\n",
        "        return bboxhead\n",
        "\n",
        "    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        landmarkhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            landmarkhead.append(LandmarkHead(inchannels,anchor_num))\n",
        "        return landmarkhead\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        out = self.body(inputs)\n",
        "\n",
        "        # FPN\n",
        "        fpn = self.fpn(out)\n",
        "\n",
        "        # SSH\n",
        "        feature1 = self.ssh1(fpn[0])\n",
        "        feature2 = self.ssh2(fpn[1])\n",
        "        feature3 = self.ssh3(fpn[2])\n",
        "        features = [feature1, feature2, feature3]\n",
        "\n",
        "        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\n",
        "        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "\n",
        "        if self.phase == 'train':\n",
        "            output = (bbox_regressions, classifications, ldm_regressions)\n",
        "        else:\n",
        "            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddrbJVu5txF0",
        "colab_type": "text"
      },
      "source": [
        "## create_ULFGFD_plus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoA5skO93vtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "def create_ULFGFD_plus(cpu = False, nms_threshold =0.3, target_size = 640, model='mnet', weights_path=None):\n",
        "  if model == \"mnet\":\n",
        "    weights_file = 'mobilenet0.25_Final.pth'\n",
        "    cfg = cfg_mnet\n",
        "    net = RetinaFace(cfg = cfg, phase = 'test')\n",
        "  elif model == \"slim\":\n",
        "    weights_file = 'slim_Final.pth'\n",
        "    cfg = cfg_slim\n",
        "    net = Slim(cfg = cfg, phase = 'test')\n",
        "  elif model == \"rfb\":\n",
        "    weights_file = 'RBF_Final.pth'\n",
        "    cfg = cfg_rfb\n",
        "    net = RFB(cfg = cfg, phase = 'test')\n",
        "  elif model == \"slim_c64\":\n",
        "    cfg = cfg_slim\n",
        "    net = Slim_c64(cfg = cfg, phase = 'test')\n",
        "  elif model == \"slim_c64_a5\":\n",
        "    cfg = {\n",
        "      'min_sizes': [[16], [32], [64], [128], [256]],\n",
        "      'steps': [8, 16, 32, 64, 128],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0\n",
        "    }\n",
        "    net = Slim_c64_a5(cfg = cfg, phase = 'test')\n",
        "  elif model == \"slim_a5\":\n",
        "    cfg = {\n",
        "      'min_sizes': [[16], [32], [64], [128], [256]],\n",
        "      'steps': [8, 16, 32, 64, 128],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0\n",
        "    }\n",
        "    net = Slim_a5(cfg = cfg, phase = 'test')\n",
        "  elif model == \"slim_a5_fpn\":\n",
        "    cfg = {\n",
        "      'min_sizes': [[16], [32], [64], [128], [256]],\n",
        "      'steps': [8, 16, 32, 64, 128],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0\n",
        "    }\n",
        "    net = Slim_a5_FPN(cfg = cfg, phase = 'test')\n",
        "  elif model == \"slim_a5_fpn2\":\n",
        "    cfg = {\n",
        "      'min_sizes': [[16], [32], [64], [128], [256]],\n",
        "      'steps': [8, 16, 32, 64, 128],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0\n",
        "    }\n",
        "    net = Slim_a5_FPN2(cfg = cfg, phase = 'test')\n",
        "  elif model == \"slim_c64_fpn\":\n",
        "    cfg = {\n",
        "      'min_sizes': [[10, 16, 24], [32, 48], [64, 96], [128, 192], [256, 384]],\n",
        "      'steps': [8, 16, 32, 64, 128],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0\n",
        "    }\n",
        "    net = Slim_c64_FPN(cfg = cfg, phase = 'test')\n",
        "  elif model == \"slim_fpn\":\n",
        "    cfg = {\n",
        "      'min_sizes': [[10, 16, 24], [32, 48], [64, 96], [128, 192], [256, 384]],\n",
        "      'steps': [8, 16, 32, 64, 128],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0\n",
        "    }\n",
        "    net = Slim_FPN(cfg = cfg, phase = 'test')\n",
        "  elif model == \"slim_fpn_dw256\":\n",
        "    cfg = {\n",
        "      'min_sizes': [[10, 16, 24], [32, 48], [64, 96], [128, 192], [256, 384]],\n",
        "      'steps': [8, 16, 32, 64, 128],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0,\n",
        "      'gpu_train': True,\n",
        "      'batch_size': 32,\n",
        "      'ngpu': 1,\n",
        "      'epoch': 250,\n",
        "      'decay1': 190,\n",
        "      'decay2': 220\n",
        "    }\n",
        "    net = Slim_FPN_dw256()\n",
        "  elif model == \"slim_a5_fpn_dw256\":\n",
        "    cfg = {\n",
        "      'min_sizes': [[16], [32], [64], [128], [256]],\n",
        "      'steps': [8, 16, 32, 64, 128],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0,\n",
        "      'gpu_train': True,\n",
        "      'batch_size': 32,\n",
        "      'ngpu': 1,\n",
        "      'epoch': 250,\n",
        "      'decay1': 190,\n",
        "      'decay2': 220\n",
        "    }\n",
        "    net = Slim_a5_FPN_dw256()\n",
        "  elif model == \"slim_64_fpnx_dw64\":\n",
        "    cfg = {\n",
        "      'min_sizes': [[10, 16, 24], [32, 48], [64, 96], [128, 192], [256, 384]],\n",
        "      'steps': [8, 16, 32, 64, 128],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0,\n",
        "      'gpu_train': True,\n",
        "      'batch_size': 32,\n",
        "      'ngpu': 1,\n",
        "      'epoch': 250,\n",
        "      'decay1': 190,\n",
        "      'decay2': 220\n",
        "    }\n",
        "    net = Slim_64_FPNx_dw64()\n",
        "  elif model == \"mnet_fixed_a0\":\n",
        "    cfg = {\n",
        "      'name': 'mobilenet0.25',\n",
        "      'min_sizes': [[16], [32, 64], [128, 256]],\n",
        "      'steps': [8, 16, 32],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0,\n",
        "      'gpu_train': True,\n",
        "      'batch_size': 32,\n",
        "      'ngpu': 1,\n",
        "      'epoch': 250,\n",
        "      'decay1': 190,\n",
        "      'decay2': 220,\n",
        "      'pretrain': False,\n",
        "      'return_layers': {'stage1': 1, 'stage2': 2, 'stage3': 3},\n",
        "      'in_channel': 32,\n",
        "      'out_channel': 64\n",
        "    }\n",
        "    net = MnetFixedA0(cfg=cfg)\n",
        "  elif model == \"mnet_no_ssh\":\n",
        "    cfg = cfg_mnet\n",
        "    net = MnetNoSsh(cfg=cfg_mnet)\n",
        "  elif model == \"mnet_ssd_fixed_a0\":\n",
        "    cfg = {\n",
        "      'name': 'mobilenet0.25',\n",
        "      'min_sizes': [[16], [32, 64], [128, 256]],\n",
        "      'steps': [8, 16, 32],\n",
        "      'variance': [0.1, 0.2],\n",
        "      'clip': False,\n",
        "      'loc_weight': 2.0,\n",
        "      'gpu_train': True,\n",
        "      'batch_size': 32,\n",
        "      'ngpu': 1,\n",
        "      'epoch': 250,\n",
        "      'decay1': 190,\n",
        "      'decay2': 220,\n",
        "      'pretrain': False,\n",
        "      'return_layers': {'stage1': 1, 'stage2': 2, 'stage3': 3},\n",
        "      'in_channel': 32,\n",
        "      'out_channel': 64\n",
        "    }\n",
        "    net = MnetSSDFixedA0(cfg=cfg)\n",
        "  elif model == \"mnet_ssd\":\n",
        "    cfg = cfg_mnet\n",
        "    net = MnetSSD(cfg=cfg)\n",
        "  elif model == \"mnet_norm\":\n",
        "    cfg = cfg_mnet\n",
        "    net = MnetNorm(cfg=cfg)\n",
        "  elif model == \"mnet_x\":\n",
        "    cfg = cfg_mnet\n",
        "    net = MnetX(cfg=cfg)\n",
        "  elif model == \"mnet_128\":\n",
        "    cfg = cfg_mnet.copy()\n",
        "    cfg['in_channel'] = 64\n",
        "    cfg['out_channel'] = 128\n",
        "    net = Mnet_128(cfg=cfg)\n",
        "  elif model == \"mnet_s1l\":\n",
        "    cfg = cfg_mnet\n",
        "    net = Mnet_s1L(cfg=cfg)\n",
        "  elif model == \"mnet_s0_160\":\n",
        "    cfg = cfg_mnet.copy()\n",
        "    cfg['steps'] = [4, 8, 16]\n",
        "    net = Mnet_s0_160(cfg=cfg)\n",
        "\n",
        "  #device = torch.device(\"cpu\" if cpu else \"cuda\")\n",
        "  if weights_path is None:\n",
        "    weights_path = './Face-Detector-1MB-with-landmark/weights/' + weights_file \n",
        "  net = load_model(net, weights_path, True)\n",
        "  net.eval()\n",
        "  def detect(img, min_score):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    max_size = target_size\n",
        "    im_shape = img.shape\n",
        "    im_size_min = np.min(im_shape[0:2])\n",
        "    im_size_max = np.max(im_shape[0:2])\n",
        "    resize = float(target_size) / float(im_size_min)\n",
        "    # prevent bigger axis from being more than max_size:\n",
        "    if np.round(resize * im_size_max) > max_size:\n",
        "        resize = float(max_size) / float(im_size_max)\n",
        "    if resize != 1:\n",
        "        img = cv2.resize(img, None, None, fx=resize, fy=resize, interpolation=cv2.INTER_LINEAR)\n",
        "    im_height, im_width, _ = img.shape\n",
        "    scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
        "    #img -= np.array([104, 117, 123]).astype('uint8')\n",
        "    #img = img.transpose(2, 0, 1).astype('float32')\n",
        "    img = np.moveaxis(img, 2, 0).astype('float32')\n",
        "    img = torch.from_numpy(img).unsqueeze(0)\n",
        "    loc, conf, landms = net(img)\n",
        "\n",
        "    #print(im_height, im_width, img.shape, resize)\n",
        "\n",
        "    priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
        "    priors = priorbox.forward()\n",
        "    prior_data = priors.data\n",
        "    boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
        "    boxes = boxes * scale\n",
        "    boxes = boxes.cpu().numpy()\n",
        "    scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
        "    landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
        "    scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
        "                            img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
        "                            img.shape[3], img.shape[2]])\n",
        "    #scale1 = scale1.to(device)\n",
        "    landms = landms * scale1\n",
        "    landms = landms.cpu().numpy()\n",
        "\n",
        "    # ignore low scores\n",
        "    inds = np.where(scores > min_score)[0]\n",
        "    boxes = boxes[inds]\n",
        "    landms = landms[inds]\n",
        "    scores = scores[inds]\n",
        "\n",
        "    # keep top-K before NMS\n",
        "    order = scores.argsort()[::-1][:100]\n",
        "    boxes = boxes[order]\n",
        "    landms = landms[order]\n",
        "    scores = scores[order]\n",
        "\n",
        "    # do NMS\n",
        "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
        "    keep = py_cpu_nms(dets, nms_threshold)\n",
        "    # keep = nms(dets, args.nms_threshold,force_cpu=args.cpu)\n",
        "    dets = dets[keep, :]\n",
        "    landms = landms[keep]\n",
        "\n",
        "\n",
        "    out_faces = []\n",
        "    for face in dets:\n",
        "      x0, y0, x1, y1, s = face[0:5]\n",
        "      x0, x1 = np.array([x0, x1]) / im_width\n",
        "      y0, y1 = np.array([y0, y1]) / im_height\n",
        "      out_faces.append([x0, y0, x1-x0, y1-y0, s])\n",
        "    return out_faces\n",
        "  return detect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTcdwFXq3-cq",
        "colab_type": "text"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HIYJE11KdU4A",
        "colab": {}
      },
      "source": [
        "from graphviz import Digraph\n",
        "import re\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Variable\n",
        "import torchvision.models as models\n",
        "from torchviz import make_dot\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "\n",
        "weights_file = 'mnet_260_640_80_epoch_249.pth'\n",
        "cfg = cfg_mnet\n",
        "net = RetinaFace(cfg = cfg, phase = 'test')\n",
        "net = load_model(net, weights_file, True)\n",
        "#net.load_state_dict(torch.load('./mobilenet0.25_Final.pth'))\n",
        "y = net(Variable(torch.from_numpy(np.zeros([3, 640, 640]).astype('float32')).unsqueeze(0)))\n",
        "\n",
        "g = make_dot(y)\n",
        "g.view()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0bhe5G84d6X",
        "colab_type": "text"
      },
      "source": [
        "# Extract Weights Mnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKjBDZMs4fNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "weights_file = 'mnet_260_640_80_epoch_249.pth'\n",
        "cfg = cfg_mnet\n",
        "net = RetinaFace(cfg = cfg, phase = 'test')\n",
        "net = load_model(net, weights_file, True)\n",
        "\n",
        "\n",
        "layers = []\n",
        "layer_names = []\n",
        "\n",
        "# BODY\n",
        "for stage, module in net.body.items():\n",
        "  for idx, seq in enumerate(module):\n",
        "    module_prefix = \"mnet/{}/conv_{}\".format(stage.replace('stage', 'stage_'), idx)\n",
        "    if stage == 'stage1' and idx == 0:\n",
        "      layer_names.append(\"{}/filters\".format(module_prefix))\n",
        "      layer_names.append(\"{}/batch_norm\".format(module_prefix))\n",
        "    else:\n",
        "      layer_names.append(\"{}/depthwise_filter\".format(module_prefix))\n",
        "      layer_names.append(\"{}/batch_norm_depthwise_conv\".format(module_prefix))\n",
        "      layer_names.append(\"{}/pointwise_filter\".format(module_prefix))\n",
        "      layer_names.append(\"{}/batch_norm_pointwise_conv\".format(module_prefix))\n",
        "    for l in seq:\n",
        "      if hasattr(l, 'weight'):\n",
        "        layers.append(l)\n",
        "\n",
        "# FPN\n",
        "for ls in [net.fpn.output3, net.fpn.output2, net.fpn.output1, net.fpn.merge2, net.fpn.merge1]:\n",
        "  for l in ls:\n",
        "    if hasattr(l, 'weight'):\n",
        "      layers.append(l)\n",
        "for name in ['conv_shrink_stage_3', 'conv_shrink_stage_2', 'conv_shrink_stage_1', 'conv_anti_aliasing_stage_2', 'conv_anti_aliasing_stage_1']:\n",
        "  layer_names.append(\"fpn/{}/filters\".format(name))\n",
        "  layer_names.append(\"fpn/{}/batch_norm\".format(name))\n",
        "\n",
        "# SSH\n",
        "for idx, ssh in enumerate([net.ssh1, net.ssh2, net.ssh3]):\n",
        "  for module in [ssh.conv3X3, ssh.conv5X5_1, ssh.conv5X5_2, ssh.conv7X7_2, ssh.conv7x7_3]:\n",
        "    for l in module:\n",
        "      if hasattr(l, 'weight'):\n",
        "        layers.append(l)\n",
        "  for name in ['conv_3x3', 'conv_5x5_1', 'conv_5x5_2', 'conv_7x7_1', 'conv_7x7_2']:\n",
        "    layer_names.append(\"ssh_{}/{}/filters\".format(idx + 1, name))\n",
        "    layer_names.append(\"ssh_{}/{}/batch_norm\".format(idx + 1, name))\n",
        "\n",
        "# HEADS\n",
        "for idx, l in enumerate(net.ClassHead):\n",
        "  layers.append(l.conv1x1)\n",
        "  layer_names.append(\"conv_score_stage_{}/filters\".format(idx + 1))\n",
        "for idx, l in enumerate(net.BboxHead):\n",
        "  layers.append(l.conv1x1)\n",
        "  layer_names.append(\"conv_box_stage_{}/filters\".format(idx + 1))\n",
        "for idx, l in enumerate(net.LandmarkHead):\n",
        "  layers.append(l.conv1x1)\n",
        "  layer_names.append(\"conv_landmarks_stage_{}/filters\".format(idx + 1))\n",
        "\n",
        "print(net.ClassHead)\n",
        "print(net.BboxHead)\n",
        "print(net.LandmarkHead)\n",
        "\n",
        "weight_names = []\n",
        "weights_array = []\n",
        "for layer, name in zip(layers, layer_names):\n",
        "  if hasattr(layer, 'running_mean'):\n",
        "    weights_array.append(layer.running_mean.detach().numpy())\n",
        "    weights_array.append(layer.running_var.detach().numpy())\n",
        "    weights_array.append(layer.weight.detach().numpy())\n",
        "    weights_array.append(layer.bias.detach().numpy())\n",
        "    weight_names.append(name + '/mean')\n",
        "    weight_names.append(name + '/variance')\n",
        "    weight_names.append(name + '/scale')\n",
        "    weight_names.append(name + '/offset')\n",
        "  else:\n",
        "    weights = layer.weight.detach().numpy()\n",
        "    if \"depthwise_filter\" in name:\n",
        "      weights = np.moveaxis(np.moveaxis(weights, 0, -1), 0, -1)\n",
        "    else:\n",
        "      weights = np.moveaxis(np.moveaxis(weights, 1, -1), 0, -1)\n",
        "    weights_array.append(weights)\n",
        "    weight_names.append(name)\n",
        "\n",
        "manifest_weights = []\n",
        "for weights, name in zip(weights_array, weight_names):\n",
        "  print(name, weights.shape, np.sum(np.abs(weights)))\n",
        "  manifest_weights.append({\n",
        "    \"name\": name, \"shape\": weights.shape, \"dtype\":\"float32\"\n",
        "  })\n",
        "\n",
        "concated_weights = np.array([])\n",
        "for weights in weights_array:\n",
        "  concated_weights = np.append(concated_weights, weights.flatten())\n",
        "  print(concated_weights.shape, np.sum(np.abs(concated_weights)))\n",
        "\n",
        "#print(concated_weights.shape)\n",
        "shard = 'mnet_260_640_80_epoch_249-shard1.bin'\n",
        "concated_weights = concated_weights.astype('float32')\n",
        "concated_weights.tofile(shard)\n",
        "print(concated_weights[0:216])\n",
        "print(concated_weights.shape)\n",
        "manifest = [{\n",
        "  \"weights\": manifest_weights,\n",
        "  \"paths\": [shard]\n",
        "}]\n",
        "\n",
        "with open('mnet_260_640_80_epoch_249.json', 'w') as file:\n",
        "  file.write(json.dumps(manifest))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAyM24tB57Zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[{\"weights\":\n",
        "  [{\"name\":\"entry_flow/conv_in/filters\",\"shape\":[3,3,3,32],\"dtype\":\"float32\",\n",
        "    \"quantization\":{\"dtype\":\"uint8\",\"scale\":0.005431825039433498,\"min\":-0.7441600304023892}},\n",
        "   {\"name\":\"entry_flow/conv_in/bias\",\"shape\":[32],\"dtype\":\"float32\"},\n",
        "   {\"name\":\"entry_flow/reduction_block_0/separable_conv0/depthwise_filter\",\"shape\":[3,3,32,1],\"dtype\":\"float32\",\n",
        "    \"quantization\":{\"dtype\":\"uint8\",\"scale\":0.005691980614381678,\"min\":-0.6090419257388395}},\n",
        "   {\"name\":\"entry_flow/reduction_block_0/separable_conv0/pointwise_filter\",\"shape\":[1,1,32,64],\"dtype\":\"float32\",\n",
        "    \"quantization\":{\"dtype\":\"uint8\",\"scale\":0.009089225881239947,\"min\":-1.1179747833925135}},\n",
        "   {\"name\":\"entry_flow/reduction_block_0/separable_conv0/bias\",\"shape\":[64],\"dtype\":\"float32\"},\n",
        "   {\"name\":\"entry_flow/reduction_block_0/separable_conv1/depthwise_filter\",\"shape\":[3,3,64,1],\"dtype\":\"float32\",\n",
        "    \"quantization\":{\"dtype\":\"uint8\",\"scale\":0.00683894624897078,\"min\":-0.8138346036275228}},\n",
        "   {\"name\":\"entry_flow/reduction_block_0/separable_conv1/pointwise_filter\",\"shape\":[1,1,64,64],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.011632566358528886,\"min\":-1.3028474321552352}},{\"name\":\"entry_flow/reduction_block_0/separable_conv1/bias\",\"shape\":[64],\"dtype\":\"float32\"},{\"name\":\"entry_flow/reduction_block_0/expansion_conv/filters\",\"shape\":[1,1,32,64],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.010254812240600587,\"min\":-0.9229331016540528}},{\"name\":\"entry_flow/reduction_block_0/expansion_conv/bias\",\"shape\":[64],\"dtype\":\"float32\"},{\"name\":\"entry_flow/reduction_block_1/separable_conv0/depthwise_filter\",\"shape\":[3,3,64,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.0052509616403018725,\"min\":-0.6406173201168285}},{\"name\":\"entry_flow/reduction_block_1/separable_conv0/pointwise_filter\",\"shape\":[1,1,64,128],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.010788509424994973,\"min\":-1.4564487723743214}},{\"name\":\"entry_flow/reduction_block_1/separable_conv0/bias\",\"shape\":[128],\"dtype\":\"float32\"},{\"name\":\"entry_flow/reduction_block_1/separable_conv1/depthwise_filter\",\"shape\":[3,3,128,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.00553213918910307,\"min\":-0.7025816770160899}},{\"name\":\"entry_flow/reduction_block_1/separable_conv1/pointwise_filter\",\"shape\":[1,1,128,128],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.013602388606351965,\"min\":-1.6186842441558837}},{\"name\":\"entry_flow/reduction_block_1/separable_conv1/bias\",\"shape\":[128],\"dtype\":\"float32\"},{\"name\":\"entry_flow/reduction_block_1/expansion_conv/filters\",\"shape\":[1,1,64,128],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.007571851038465313,\"min\":-1.158493208885193}},{\"name\":\"entry_flow/reduction_block_1/expansion_conv/bias\",\"shape\":[128],\"dtype\":\"float32\"},{\"name\":\"middle_flow/main_block_0/separable_conv0/depthwise_filter\",\"shape\":[3,3,128,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.005766328409606335,\"min\":-0.6688940955143349}},{\"name\":\"middle_flow/main_block_0/separable_conv0/pointwise_filter\",\"shape\":[1,1,128,128],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.012136116214826995,\"min\":-1.5776951079275094}},{\"name\":\"middle_flow/main_block_0/separable_conv0/bias\",\"shape\":[128],\"dtype\":\"float32\"},{\"name\":\"middle_flow/main_block_0/separable_conv1/depthwise_filter\",\"shape\":[3,3,128,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.004314773222979377,\"min\":-0.5652352922102984}},{\"name\":\"middle_flow/main_block_0/separable_conv1/pointwise_filter\",\"shape\":[1,1,128,128],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.01107162026798024,\"min\":-1.2400214700137868}},{\"name\":\"middle_flow/main_block_0/separable_conv1/bias\",\"shape\":[128],\"dtype\":\"float32\"},{\"name\":\"middle_flow/main_block_0/separable_conv2/depthwise_filter\",\"shape\":[3,3,128,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.0036451735917259667,\"min\":-0.4848080876995536}},{\"name\":\"middle_flow/main_block_0/separable_conv2/pointwise_filter\",\"shape\":[1,1,128,128],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.008791744942758598,\"min\":-1.134135097615859}},{\"name\":\"middle_flow/main_block_0/separable_conv2/bias\",\"shape\":[128],\"dtype\":\"float32\"},{\"name\":\"middle_flow/main_block_1/separable_conv0/depthwise_filter\",\"shape\":[3,3,128,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.004915751896652521,\"min\":-0.6095532351849126}},{\"name\":\"middle_flow/main_block_1/separable_conv0/pointwise_filter\",\"shape\":[1,1,128,128],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.010868691463096469,\"min\":-1.3368490499608656}},{\"name\":\"middle_flow/main_block_1/separable_conv0/bias\",\"shape\":[128],\"dtype\":\"float32\"},{\"name\":\"middle_flow/main_block_1/separable_conv1/depthwise_filter\",\"shape\":[3,3,128,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.005010117269029804,\"min\":-0.6012140722835765}},{\"name\":\"middle_flow/main_block_1/separable_conv1/pointwise_filter\",\"shape\":[1,1,128,128],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.010311148213405235,\"min\":-1.3816938605963016}},{\"name\":\"middle_flow/main_block_1/separable_conv1/bias\",\"shape\":[128],\"dtype\":\"float32\"},{\"name\":\"middle_flow/main_block_1/separable_conv2/depthwise_filter\",\"shape\":[3,3,128,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.004911523706772748,\"min\":-0.7367285560159123}},{\"name\":\"middle_flow/main_block_1/separable_conv2/pointwise_filter\",\"shape\":[1,1,128,128],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.008976466047997568,\"min\":-1.2207993825276693}},{\"name\":\"middle_flow/main_block_1/separable_conv2/bias\",\"shape\":[128],\"dtype\":\"float32\"},{\"name\":\"exit_flow/reduction_block/separable_conv0/depthwise_filter\",\"shape\":[3,3,128,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.005074804436926748,\"min\":-0.7104726211697447}},{\"name\":\"exit_flow/reduction_block/separable_conv0/pointwise_filter\",\"shape\":[1,1,128,256],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.011453078307357489,\"min\":-1.4545409450344011}},{\"name\":\"exit_flow/reduction_block/separable_conv0/bias\",\"shape\":[256],\"dtype\":\"float32\"},{\"name\":\"exit_flow/reduction_block/separable_conv1/depthwise_filter\",\"shape\":[3,3,256,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.007741751390344957,\"min\":-1.1380374543807086}},{\"name\":\"exit_flow/reduction_block/separable_conv1/pointwise_filter\",\"shape\":[1,1,256,256],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.011347713189966538,\"min\":-1.497898141075583}},{\"name\":\"exit_flow/reduction_block/separable_conv1/bias\",\"shape\":[256],\"dtype\":\"float32\"},{\"name\":\"exit_flow/reduction_block/expansion_conv/filters\",\"shape\":[1,1,128,256],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.006717281014311547,\"min\":-0.8329428457746318}},{\"name\":\"exit_flow/reduction_block/expansion_conv/bias\",\"shape\":[256],\"dtype\":\"float32\"},{\"name\":\"exit_flow/separable_conv/depthwise_filter\",\"shape\":[3,3,256,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.0027201742518181892,\"min\":-0.3237007359663645}},{\"name\":\"exit_flow/separable_conv/pointwise_filter\",\"shape\":[1,1,256,512],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.010076364348916447,\"min\":-1.330080094056971}},{\"name\":\"exit_flow/separable_conv/bias\",\"shape\":[512],\"dtype\":\"float32\"},{\"name\":\"fc/age/weights\",\"shape\":[512,1],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.008674054987290326,\"min\":-1.2664120281443876}},{\"name\":\"fc/age/bias\",\"shape\":[1],\"dtype\":\"float32\"},{\"name\":\"fc/gender/weights\",\"shape\":[512,2],\"dtype\":\"float32\",\"quantization\":{\"dtype\":\"uint8\",\"scale\":0.0029948226377075793,\"min\":-0.34140978069866407}},{\"name\":\"fc/gender/bias\",\"shape\":[2],\"dtype\":\"float32\"}\n",
        "   ],\"paths\":[\"age_gender_model-shard1\"]}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ900YitOJAi",
        "colab_type": "text"
      },
      "source": [
        "# Debug Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i0zpdHkOLjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models.detection.backbone_utils as backbone_utils\n",
        "import torchvision.models._utils as _utils\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "from models.net import MobileNetV1 as MobileNetV1\n",
        "from models.net import FPN as FPN\n",
        "from models.net import SSH as SSH\n",
        "\n",
        "\n",
        "\n",
        "class ClassHead(nn.Module):\n",
        "    def __init__(self,inchannels=512,num_anchors=3):\n",
        "        super(ClassHead,self).__init__()\n",
        "        self.num_anchors = num_anchors\n",
        "        self.conv1x1 = nn.Conv2d(inchannels,self.num_anchors*2,kernel_size=(1,1),stride=1,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.conv1x1(x)\n",
        "        out = out.permute(0,2,3,1).contiguous()\n",
        "        \n",
        "        return out.view(out.shape[0], -1, 2)\n",
        "\n",
        "class BboxHead(nn.Module):\n",
        "    def __init__(self,inchannels=512,num_anchors=3):\n",
        "        super(BboxHead,self).__init__()\n",
        "        self.conv1x1 = nn.Conv2d(inchannels,num_anchors*4,kernel_size=(1,1),stride=1,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.conv1x1(x)\n",
        "        out = out.permute(0,2,3,1).contiguous()\n",
        "\n",
        "        return out.view(out.shape[0], -1, 4)\n",
        "\n",
        "class LandmarkHead(nn.Module):\n",
        "    def __init__(self,inchannels=512,num_anchors=3):\n",
        "        super(LandmarkHead,self).__init__()\n",
        "        self.conv1x1 = nn.Conv2d(inchannels,num_anchors*10,kernel_size=(1,1),stride=1,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.conv1x1(x)\n",
        "        out = out.permute(0,2,3,1).contiguous()\n",
        "\n",
        "        return out.view(out.shape[0], -1, 10)\n",
        "\n",
        "class RetinaFace(nn.Module):\n",
        "    def __init__(self, cfg = None, phase = 'train'):\n",
        "        \"\"\"\n",
        "        :param cfg:  Network related settings.\n",
        "        :param phase: train or test.\n",
        "        \"\"\"\n",
        "        super(RetinaFace,self).__init__()\n",
        "        self.phase = phase\n",
        "        backbone = None\n",
        "        if cfg['name'] == 'mobilenet0.25':\n",
        "            backbone = MobileNetV1()\n",
        "            if cfg['pretrain']:\n",
        "                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\n",
        "                from collections import OrderedDict\n",
        "                new_state_dict = OrderedDict()\n",
        "                for k, v in checkpoint['state_dict'].items():\n",
        "                    name = k[7:]  # remove module.\n",
        "                    new_state_dict[name] = v\n",
        "                # load params\n",
        "                backbone.load_state_dict(new_state_dict)\n",
        "        elif cfg['name'] == 'Resnet50':\n",
        "            import torchvision.models as models\n",
        "            backbone = models.resnet50(pretrained=cfg['pretrain'])\n",
        "\n",
        "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
        "        in_channels_stage2 = cfg['in_channel']\n",
        "        in_channels_list = [\n",
        "            in_channels_stage2 * 2,\n",
        "            in_channels_stage2 * 4,\n",
        "            in_channels_stage2 * 8,\n",
        "        ]\n",
        "        out_channels = cfg['out_channel']\n",
        "        self.fpn = FPN(in_channels_list,out_channels)\n",
        "        self.ssh1 = SSH(out_channels, out_channels)\n",
        "        self.ssh2 = SSH(out_channels, out_channels)\n",
        "        self.ssh3 = SSH(out_channels, out_channels)\n",
        "\n",
        "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
        "\n",
        "    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        classhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            classhead.append(ClassHead(inchannels,anchor_num))\n",
        "        return classhead\n",
        "    \n",
        "    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        bboxhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            bboxhead.append(BboxHead(inchannels,anchor_num))\n",
        "        return bboxhead\n",
        "\n",
        "    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
        "        landmarkhead = nn.ModuleList()\n",
        "        for i in range(fpn_num):\n",
        "            landmarkhead.append(LandmarkHead(inchannels,anchor_num))\n",
        "        return landmarkhead\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        out = self.body(inputs)\n",
        "\n",
        "        # FPN\n",
        "        fpn = self.fpn(out)\n",
        "\n",
        "        # SSH\n",
        "        feature1 = self.ssh1(fpn[0])\n",
        "        feature2 = self.ssh2(fpn[1])\n",
        "        feature3 = self.ssh3(fpn[2])\n",
        "        features = [feature1, feature2, feature3]\n",
        "\n",
        "        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\n",
        "        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
        "\n",
        "        if self.phase == 'train':\n",
        "            output = (bbox_regressions, classifications, ldm_regressions)\n",
        "        else:\n",
        "            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
        "        return output\n",
        "   \n",
        "from augment.augment import abs_coords\n",
        "\n",
        "def draw_box(img, box, color = (255, 0, 0)):\n",
        "  x, y, w, h = abs_coords(box, img)\n",
        "\n",
        "  cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
        "  cv2.circle(img, (x, y), 2, (0, 0, 255), -1)\n",
        "  cv2.circle(img, (x, y + h), 2, (0, 0, 255), -1)\n",
        "  cv2.circle(img, (x + w, y), 2, (0, 0, 255), -1)\n",
        "  cv2.circle(img, (x + w, y + h), 2, (0, 0, 255), -1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34EoW60sP0K0",
        "colab_type": "text"
      },
      "source": [
        "#a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpkTIODDPzvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "c50900f4-b952-4aa2-90ca-4d8c81e03efd"
      },
      "source": [
        "weights_file = 'mnet_260_640_80_epoch_249.pth'\n",
        "cfg = cfg_mnet\n",
        "net = RetinaFace(cfg = cfg, phase = 'test')\n",
        "net = load_model(net, weights_file, True)\n",
        "net.eval()\n",
        "target_size = 640\n",
        "min_score = 0.5\n",
        "\n",
        "img = cv2.imread('./got.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "max_size = target_size\n",
        "im_shape = img.shape\n",
        "im_size_min = np.min(im_shape[0:2])\n",
        "im_size_max = np.max(im_shape[0:2])\n",
        "resize = float(target_size) / float(im_size_min)\n",
        "# prevent bigger axis from being more than max_size:\n",
        "if np.round(resize * im_size_max) > max_size:\n",
        "    resize = float(max_size) / float(im_size_max)\n",
        "if resize != 1:\n",
        "    img = cv2.resize(img, None, None, fx=resize, fy=resize, interpolation=cv2.INTER_LINEAR)\n",
        "im_height, im_width, _ = img.shape\n",
        "scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
        "#img -= np.array([104, 117, 123]).astype('uint8')\n",
        "#img = img.transpose(2, 0, 1).astype('float32')\n",
        "img = np.moveaxis(img, 2, 0).astype('float32')\n",
        "img = torch.from_numpy(img).unsqueeze(0)\n",
        "loc, conf, landms = net(img)\n",
        "\n",
        "print(conf.shape)\n",
        "conf = np.moveaxis(conf.detach().numpy(), 2, 0)\n",
        "print(conf.shape)\n",
        "*score, = conf\n",
        "score = score[1]\n",
        "print(score.shape)\n",
        "loc = loc.detach().numpy()\n",
        "scores = score[score > min_score]\n",
        "boxes = loc[np.where(score > min_score)]\n",
        "print(score.shape)\n",
        "print(scores.shape)\n",
        "print(boxes.shape)\n",
        "\n",
        "for box, s in zip(boxes, scores):\n",
        "  print(s, box)\n",
        "\n",
        "\n",
        "!rm -rf ./check_inputs && mkdir ./check_inputs\n",
        "\n",
        "for box in boxes:\n",
        "  print(box)\n",
        "  draw_box(img, box, color = (255, 0, 0))\n",
        "file = './check_inputs/' + str(idx) + '.jpg'\n",
        "cv2.imwrite(file, img)\n",
        "display(Image(file))\n",
        "    \n",
        "!rm -rf ./check_inputs"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model from mnet_260_640_80_epoch_249.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "torch.Size([1, 16800, 2])\n",
            "(2, 1, 16800)\n",
            "(1, 16800)\n",
            "(1, 16800)\n",
            "(17,)\n",
            "(17, 4)\n",
            "0.9223244 [ 0.01361381  2.6572025  -1.1807798   0.20542033]\n",
            "0.9625837 [ 2.3740065   0.16957198 -1.311083    0.14386286]\n",
            "0.9858867 [-0.00292785  0.20133093 -1.3019291   0.15209888]\n",
            "0.95992523 [-2.5032153   0.2269468  -1.2399713   0.09710193]\n",
            "0.83198255 [ 2.3168056  -2.1022317  -1.0914615  -0.03128243]\n",
            "0.9519877 [ 0.06264611 -2.453569   -1.2198281   0.14741793]\n",
            "0.947363 [ 0.32183662  2.6478448  -1.246248    0.0826387 ]\n",
            "0.82353264 [ 2.381438   -0.5199982  -2.019539   -0.73138475]\n",
            "0.9790206 [ 2.4727626   0.18646555 -1.2337285   0.0735984 ]\n",
            "0.99245 [ 0.21699834  0.2627897  -1.3449548  -0.04531649]\n",
            "0.9835163 [-2.327283    0.23459072 -1.3965985  -0.01298298]\n",
            "0.8809256 [ 0.50878936  0.22909369 -1.59382    -0.2055574 ]\n",
            "0.9021648 [-2.0384395   0.21936119 -1.6624112  -0.31590834]\n",
            "0.8103047 [ 2.4321291  -2.1504915  -1.0994612  -0.10681025]\n",
            "0.9760419 [ 0.23374797 -2.3702636  -1.2980862  -0.02474141]\n",
            "0.8823553 [-2.3342085  -2.228711   -1.3514205  -0.02885973]\n",
            "0.85405016 [ 0.44131744 -2.131467   -1.6808175  -0.27822727]\n",
            "[ 0.01361381  2.6572025  -1.1807798   0.20542033]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-0a314cd430a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0mdraw_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./check_inputs/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-2e061ea466f5>\u001b[0m in \u001b[0;36mdraw_box\u001b[0;34m(img, box, color)\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type tuple)"
          ]
        }
      ]
    }
  ]
}